

# **开发小笔记**

```python
# -*- coding:utf-8 -*-
"""
Description:
@author: Yaoyk
@date: 2022-06-12
"""
```

```markdown
Better late than never.Late is better than not to come.
迟做总比不做好；晚来总比不来强。
```



## 一、**算法**

### 1. **二分查找**

- 思想：思想:取一个索引开头left,取一个索引末尾(len(队列)-1)right,让你的值跟(left + right)//2(middle)比。如果索引middle值比你查的值大,把middle赋值给right,反之把middle赋值给left。

**（1）该数组，必须是有序：**

1. 二分查找依赖的是**顺序表结构**，即**数组**。
2. 二分查找针对的是有序数据，因此只能用在插入、删除操作不频繁，一次排序多次查找的场景中。

**（2）对数据量大小有要求**：

1. 数据量太小不适合二分查找，与直接遍历相比效率提升不明显。但有一个例外，就是数据之间的比较操作非常费时，比如数组中存储的都是组成长度超过100的字符串。
2. 数据量太大也不适合用二分查找，因为数组需要连续的空间，若数据量太大，往往找不到存储如此大规模数据的连续内存空间。

**（3）一般要求找到的是某一个值或一个位置**

### 2. 孤立森林

孤立森林官方接口：https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html#sklearn.ensemble.IsolationForest



**基本用法：**

```python
sklearn.ensemble.IsolationForest(
              *, 
              n_estimators=100, 
              max_samples='auto', 
              contamination='auto', 
              max_features=1.0, 
              bootstrap=False, 
              n_jobs=None, 
              random_state=None, 
              verbose=0, 
              warm_start=False)
```

**参数详解：**

```python
n_estimators : int, optional (default=100)

iTree的个数，指定该森林中生成的随机树数量，默认为100个

max_samples : int or float, optional (default=”auto”)

构建子树的样本数，整数为个数，小数为占全集的比例，用来训练随机数的样本数量，即子采样的大小

如果设置的是一个int常数，那么就会从总样本X拉取max_samples个样本来生成一棵树iTree

如果设置的是一个float浮点数，那么就会从总样本X拉取max_samples * X.shape[0]个样本,X.shape[0]表示总样本个数

如果设置的是"auto"，则max_samples=min(256, n_samples)，n_samples即总样本的数量

如果max_samples值比提供的总样本数量还大的话，所有的样本都会用来构造数，意思就是没有采样了，构造的n_estimators棵iTree使用的样本都是一样的，即所有的样本

contamination : float in (0., 0.5), optional (default=0.1)

取值范围为(0., 0.5),表示异常数据占给定的数据集的比例，数据集中污染的数量，其实就是训练数据中异常数据的数量，比如数据集异常数据的比例。定义该参数值的作用是在决策函数中定义阈值。如果设置为'auto'，则决策函数的阈值就和论文中定义的一样

max_features : int or float, optional (default=1.0)

构建每个子树的特征数，整数位个数，小数为占全特征的比例，指定从总样本X中抽取来训练每棵树iTree的属性的数量，默认只使用一个属性

如果设置为int整数，则抽取max_features个属性

如果是float浮点数，则抽取max_features * X.shape[1]个属性

bootstrap : boolean, optional (default=False)
采样是有放回还是无放回，如果为True，则各个树可放回地对训练数据进行采样。如果为False，则执行不放回的采样。

n_jobs :int or None, optional (default=None)
在运行fit()和predict()函数时并行运行的作业数量。除了在joblib.parallel_backend上下文的情况下，None表示为1。设置为-1则表示使用所有可用的处理器

random_state : int, RandomState instance or None, optional (default=None)

每次训练的随机性

如果设置为int常数，则该random_state参数值是用于随机数生成器的种子

如果设置为RandomState实例，则该random_state就是一个随机数生成器

如果设置为None，该随机数生成器就是使用在np.random中的RandomState实例

verbose : int, optional (default=0)

训练中打印日志的详细程度，数值越大越详细

warm_start : bool, optional (default=False)
当设置为True时，重用上一次调用的结果去fit,添加更多的树到上一次的森林1集合中；否则就fit一整个新的森林

3、属性
base_estimator_：The child estimator template used to create the collection of fitted sub-estimators.

estimators_：list of ExtraTreeRegressor instances The collection of fitted sub-estimators.

estimators_：features_list of ndarray The subset of drawn features for each base estimator.

estimators_samples_：list of ndarray The subset of drawn samples for each base estimator.

max_samples_：The actual number of samples

n_features_：DEPRECATED: Attribute n_features_ was deprecated in version 1.0 and will be removed in 1.2.

n_features_in_：Number of features seen during fit.

feature_names_in_：Names of features seen during fit. Defined only when X has feature names that are all strings

4、方 法
fit(X[, y, sample_weight])：训练模型

decision_function(X)：返回平均异常分数

predict(X)：预测模型返回1或者-1

fit_predict(X[, y])：训练-预测模型一起完成

get_params([deep])：Get parameters for this estimator.

score_samples(X)：Opposite of the anomaly score defined in the original paper.

set_params(**params)：Set the parameters of this estimator.

```

**算法实现：**

```python
# -*- coding: utf-8 -*-

# 加载模型所需要的的包
import pandas  as pd
from sklearn.ensemble import IsolationForest
import warnings
warnings.filterwarnings('ignore')


# 构造一个数据集，只包含一列数据，假如都是月薪数据，有些可能是错的
df = pd.DataFrame({'salary':[4,1,4,5,3,6,2,5,6,2,5,7,1,8,12,33,4,7,6,7,8,55]})


#构建模型 ,n_estimators=100 ,构建100颗树
model = IsolationForest(n_estimators=100,
                      max_samples='auto',
                      contamination=float(0.1),
                      max_features=1.0)
# 训练模型
model.fit(df[['salary']])

# 预测 decision_function 可以得出 异常评分
df['scores']  = model.decision_function(df[['salary']])

#  predict() 函数 可以得到模型是否异常的判断，-1为异常，1为正常
df['anomaly'] = model.predict(df[['salary']])
print(df)

```



## 二、Jupyter快捷操作



|   Markdown    |         功能          |
| :-----------: | :-------------------: |
|      m/y      |      切换状态栏       |
|     -空格     |       无序列表        |
|    1.空格     |       有序列表        |
| ```python ``` |    插入python代码     |
|  **代码块**   |       **功能**        |
|      dd       |      删除单元格       |
|   L/shift+L   | 切换行号/切换所有行号 |
|    shift+m    |      合并单元格       |
| ctrl+shift+-  |      拆分单元格       |
|      a/b      |      插入单元格       |

### 1. Jupyter Notebook有两种mode

- Enter：进入edit模式
- Esc：进入command模式

### 2. Command命令快捷键：

- A：在上方增加一个cell
- B：在下方增加一个cell
- X：剪切该cell
- C：复制该cell
- V：在该cell下方粘贴复制的cell
- Shift-V：在该cell上方粘贴复制的cell
- L：隐藏、显示当前cell的代码行号
- shift-L：隐藏/显示所有cell的代码行号
- O：隐藏该cell的output
- DD：删除这个cell
- Z：撤销删除操作
- Y：转为code模式
- M：转为markdown模式
- R：转为raw模式
- H：展示快捷键帮助
- Shift-Enter：运行本单元，选中下个单元 新单元默认为command模式
- Ctrl-Enter 运行本单元
- Alt-Enter 运行本单元，在其下插入新单元 新单元默认为edit模式
- OO：重启当前kernal
- II：打断当前kernal的运行
- shift+上/下：向上/下选中多个代码块
- 上/下：向上/下选中代码块
- F：查找替换

### 3. Edit命令快捷键：

- Tab：代码补全
- ctrl]或Tab：缩进（向右）
- ctrl[或shift-Tab：反缩进（向左）
- ctrl A：全选
- ctrl D：删除整行
- ctrl Z：撤销





## 三、**Python** Q&A

### **1. Pandas→mysql**

```markdown
Q: Pandas to Mysql AttributeError: ‘Timestamp‘ object has no attribute ‘translate‘
```

```python
rst['ds'] = rst['ds'].apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S'))

warn_day_hour['date_day'] = warn_day_hour['date_day'].astype(str)
```



### **2. pandas高级接口--时间(.dt)**

```python
dt.year

dt.month

dt.day

dt.hour

dt.minute

dt.second

dt.week

# (dt.weekofyear和dt.week一样)分别返回日期的年、月、日、小时、分、秒及一年中的第几周
```



### **3. 提取每小时，切片**

```python
for m in range(6,24):
    a=0
    for i in range(len(df)):
        if int(df.iloc[i]['计划时间']**[:2])** == m:
            a+=df.iloc[i]['承载人数']
    print(a)
```



### **4. 去重**

#### （1）去除完全重复的行数据

```python
data.drop_duplicates(inplace=True)
```

#### （2）去除某几列重复的行数据

```python
data.drop_duplicates(subset=['A','B'],keep='first',inplace=True)
```

**subset：** 列名，可选，默认为None

**keep：** {‘first’, ‘last’, False}, 默认值 ‘first’

**first：** 保留第一次出现的重复行，删除后面的重复行。

**last：** 删除重复项，除了最后一次出现。

**False：** 删除所有重复项。

**inplace：**布尔值，默认为False，是否直接在原数据上删除重复项或删除重复项后返回副本。（inplace=True表示直接在原来的DataFrame上删除重复项，而默认值False表示生成一个副本。）

#### （3）去除重复列

```python
df_merge_out_plan_tmp = df_merge_out_plan_tmp.T.drop_duplicates().T
```



### **5. 表关联**

（1）多表

```python
# 4表关联, projid
df_merge = reduce(lambda x, y: pd.merge(x, y, on=['PROJID']), [df_1, df_2, df_3, df_4])  # PROJID*4表
```

（2）两表

```python
df_merge1 = pd.merge(df_1, df_2, how='inner', on='key')

df_merge = pd.merge(dfl,df2,left_on='key',right_on='key) # 左右字段不一样

pd.merge(df_1,df_2,on=['id','subject_id'])
```



### **6. 删除指定列**

```python
df = df.drop(columns=['date', 'month'])
```

```python
df.drop(df.index[0], inplace=True)    # 删除第1行
df.drop(df.index[0:3], inplace=True)   # 删除前3行
df.drop(df.index[[0, 2]], inplace=True) # 删除第1第3行
```



### **7. 删除空值行**、列

（1）

```python
df_approve_out = df_approve_out[~(df_approve_out['anomaly_style'].isnull())] #删掉空行

df = df.dropna(axis=0)  # 删除有空值的行，使用参数axis=0

df = df.dropna(axis=1) #删除有空值的列，使用参数axis=1
```

（2）

```python
# 删除anomaly_style空值行

unique_anomaly_style = df_approve_out['anomaly_style'].astype(str).unique()

unique_anomaly_style = [i for i in unique_anomaly_style if i != '']

df_approve_out = df_approve_out[df_approve_out['anomaly_style'].isin(unique_anomaly_style)]

df = df.dropna(subset=['name','team'])
```



### **8. 排序**

#### (1)pandas

inplace：是否修改原始DataFrame

当 **inplace = False** 时，返回为修改过的数据，原数据不变。

当 **inplace = True** 时，返回值为 None，直接在原数据上进行操作。



升：

```python
df.sort_values(by='price', inplace=True)
```

降：

```python
df.sort_values(by='price', inplace=True, ascending=False)
```

```python
data.sort_values(by='AdmissionDate')    # 日期升序
```

```python
# python>>>>>>>>>>>>>>

# sort的参数reverse 可以控制排序规则，reverse为True 时是降序， reverse为False时是升序（默认），运行如图所示的程序，进行升序排序。

a.sort(reverse=False)
```

记得重置索引

```python
df = df.reset_index(drop=True)
```

#### (2) python->list

```python
# list.sort()方法
# iterable.sort(self,key,reverse)
# iterable以为可迭代对象，可以是列表、集合、字典
# key是函数，指定取待排序元素的函数规则

reverse实现降序排序，需要提供一个bool值，默认为False（升序）

L=[8,2,50,3]
L.sort()
print(L)
```

```python
# sorted()函数
# sorted(iterable,key=None,reverse=False)
# key:通过这个参数可以自定义排序逻辑

L=[8,2,50,3]
l=sorted(L)
print(l)
```



### **9. dataframe为空**

```python
if not df.empty:

# 如果df为空，则 df.empty 返回 True，反之 返回False。

rst = rst.where(rst.notnull(), None)      # 若dataframe有空值，则转换为None写入
```



### **10. 重新索引**

```python
# 不保留原来的索引，drop=True
df = df.reset_index(drop=True)
# 原始数据中某些列有None，报错，加inplace=True
df = df.reset_index(drop=True, inplace=True)
```



### **11. 时间转换**

```python
df['日期'] = pd.to_datetime(df['日期'], format='%Y-%m-%d')  #转化为时间格式
```



### **12. 保留两位**小数

```python
df_merge = df_merge.round({'wait_time': 2}) # 保留两位

df_merge = round(df_merge['wait_time'], 2) # 保留两位
```



### **13. 获取周几**

```python
df = pd.DataFrame(pd.date_range(start='2020-05-01', end='2020-06-05'))

df[1] = df[0].dt.dayofweek + 1

df.head(10)

#########################
# dt的其他常用属性和方法如下：

df['日期'].dt.day   # 提取日期

df['日期'].dt.year # 提取年份

df['日期'].dt.hour # 提取小时

df['日期'].dt.minute # 提取分钟

df['日期'].dt.second # 提取秒

df['日期'].dt.week # 一年中的第几周

df['日期'].dt.weekday # **返回一周中的星期几，0代表星期一，6代表星期天**

df['日期'].dt.dayofyear # 返回一年的第几天

df['日期'].dt.quarter # 得到每个日期分别是第几个季度。

df['日期'].dt.is_month_start # 判断日期是否是每月的第一天

df['日期'].dt.is_month_end # 判断日期是否是每月的最后一天

df['日期'].dt.is_leap_year # 判断是否是闰年

df['日期'].dt.month_name() # 返回月份的英文名称

df['日期'].dt.to_period('Q') # M 表示月份，Q 表示季度，A 表示年度，D 表示按天

df['日期'].dt.weekday_name # 返回星期几的英文 由于pandas版本问题，改变pandas版本在cmd中输入：pip install --upgrade pandas==0.25.3

Series.dt.normalize() # 函数将给定系列对象中的时间转换为午夜。
```



### **14. pop删除函数**

```python
popped_num = t1.pop(0)   

#pop()函数，从列表取出第0个元素将其存储在popped_num，并删除
```



### **15. 空值赋0**

```python
mydf['列名']=mydf['列名'].fillna(0)
```

python中，如何初始化不同的变量类型为空值

| 变量类型 |  空值   |
| :------: | :-----: |
|  字符串  |   “ ”   |
|   数值   | 0或None |
|   列表   |   []    |
|   字典   |   {}    |
|   元组   |   ()    |



```python
# 遇到None

df.isnull() # 查找
```



### 16. 列重命名

#### (1) 部分列重命名

```python
# 部分列重命名
# 没有指定inplace=True， df本身的列名并没有改变。
df.rename(columns={'a': 'A'})
# 原数据会改变
df.rename(columns={'a': 'A'}, inplace=True)
# 通过赋值对新数据列改名
df2 = df.rename(columns={'a': 'A'})
```

#### (2) 全部列重命名

```python
# 全部列重命名，直接改变了原始数据
df.columns = ['a1', 'b1', 'c1', 'd1']
```

#### (3) str 批量修改列名

```python
# str 批量修改列名
df.columns = df.columns.str.replace('1', '2')
```

### 17.1 取整(python)

#### （1）向下取整

向下取整直接用内建的 `int()` 函数即可：

```python
>>> a = 3.75
>>> int(a)
3
```

#### （2）四舍五入

对数字进行四舍五入用 `round()` 函数：

```python
>>> round(3.25); round(4.85)
3.0
5.0
```

#### （3）向上取整

向上取整需要用到 `math` 模块中的 `ceil()` 方法:

```python
>>> import math
>>> math.ceil(3.25)
4.0
>>> math.ceil(3.75)
4.0
>>> math.ceil(4.85)
5.0
```

#### （4）分别取整数部分和小数部分

有时候我们可能需要分别获取整数部分和小数部分，这时可以用 `math` 模块中的 `modf()` 方法，该方法返回一个包含小数部分和整数部分的元组：

```python
>>> import math
>>> math.modf(3.25)
(0.25, 3.0)
>>> math.modf(3.75)
(0.75, 3.0)
>>> math.modf(4.2)
(0.20000000000000018, 4.0)
```

### 17.2 取整(pandas)

#### (1)将数值四舍五入到N位小数

```python
df['a'].round(N)
```

#### (2)向上舍入

```python
np.ceil(df['a'])

df['a'].apply(np.ceil)
```

#### (3)向下舍入

```python
df['a'].apply(np.floor)
```

#### (4)四舍五入到最接近的千位数

```python
# pandas round()方法实际上允许输入负数。负输入指定小数点左侧的位置数。例如：
# 四舍五入（小数=-1）：四舍五入到最接近的十
# 四舍五入（小数=-2）：四舍五入到最接近的百位数

# 要四舍五入到最接近的千位数，只需设置decimals=-3
df['a'].round(-3)
```

#### (5)用不同的条件对数据框架进行取整

```python
# round()方法中的decimals参数可以是整数值，也可以是字典。这使得同时对多个列进行取整变得容易。

# 可以将第一列四舍五入到2位小数，并将第二列四舍五入到最接近的千位

df.round({'a':2, 'b':-3})
```

### 18. 输出excel

#### (1) 输出单个sheet

```python
import pandas as pd
 
df = pd.DataFrame({
    '销量': [10, 20],
    '售价': [100.123, None],
}, index=['aaa', 'bbb'])
df.index.name = '货号'
df.to_excel('tb.xlsx',            # 路径和文件名
            sheet_name='tb1',     # sheet 的名字
            float_format='%.2f',  # 保留两位小数
            na_rep='我是空值')     # 空值的显示
```

#### (2)不输出 index

```python
df.to_excel('tb.xlsx', index=False)
```

#### (3)输出多个sheet, 并设置输出的日期格式 (不输出时分秒)

```python
import pandas as pd
from datetime import datetime
 
df1 = pd.DataFrame(
    {'日期': [datetime(2020, 1, 1), datetime(2020, 1, 2)],
     '销量': [10, 20]}
)
 
df2 = pd.DataFrame(
    {'日期': [datetime(2020, 2, 1), datetime(2020, 2, 2)],
     '销量': [15, 25]}
)
 
with pd.ExcelWriter(
    'tb.xlsx',
    datetime_format='YYYY-MM-DD'  # 只显示年月日, 不显示时分秒
) as writer:
    df1.to_excel(writer, sheet_name='1月')  # Sheet1
    df2.to_excel(writer, sheet_name='2月')  # Sheet2
```

### 19. 分组

(1)求平均

```python
df_time_servicet = df_tmp_servicet.groupby(['DSC_CITY', 'DSC_ADM_REGION', 'HANDER_DEPTNAME', 'SERVICENAME', 'banjie_month', 'INFOTYPE'], as_index=False)['time_limit'].mean()
```

(2)统计

```python
df_node_num_region = df_node_tmp_region.groupby(['PROJID', 'DSC_CITY', 'DSC_ADM_REGION', 'banjie_month'], as_index=False)['NODE_NAME'].count()
```

```markdown
by：用于确定 groupby 的组。 如果 by 是一个函数，它会在对象索引的每个值上调用。 如果传递了 dict 或 Series，则 Series 或 dict VALUES 将用于确定组（Series 的值首先对齐；参见 .align() 方法）。 如果传递了长度等于所选轴的列表或 ndarray，则按原样使用这些值来确定组。 一个标签或标签列表可以通过 self 中的列传递给 group。 请注意，元组被解释为（单个）键。

axis：沿行 (0) 或列 (1) 拆分。

level：如果轴是MultiIndex(层次化)，则按一个或多个特定级别进行分组。

as_index：对于聚合输出，返回具有组标签作为索引的对象。仅与DataFrame输入相关。as index=False是有效的sql风格的分组输出。

sort：对组键进行排序。 关闭此功能可获得更好的性能。 请注意，这不会影响每组内的观察顺序。 Groupby 保留每个组内的行顺序。

group_keys：当调用apply时，将组键添加到index以识别片段。

squeeze：如果可能，降低返回类型的维数，否则返回一致的类型。

observed：这仅适用于任何 groupers 是分类的。 如果为真：仅显示分类分组的观察值。 如果为 False：显示分类分组的所有值。

dropna：如果为 True，并且组键包含 NA 值，则 NA 值连同行/列将被删除。 如果为 False，NA 值也将被视为组中的键。
```



### 20. 合并

```python
# 初始化两个DataFrame对象
df1 = pd.DataFrame([['a', 1], ['b', 2]],
                columns=['letter', 'number'])

df2 = pd.DataFrame([['c', 3], ['d', 4]],
                  columns=['letter', 'number'])

display(df1)
display(df2)
```

![image-20221026141406245](笔记图片/image-20221026141406245.png)

![image-20221026141415816](笔记图片/image-20221026141415816.png)

#### （1）纵向连接DataFrame对象

##### 	a. 两个DataFrame对象的列完全相同

```python
# 合并对象
pd.concat([df1, df2])
```

concat默认纵向连接DataFrame对象， 并且合并之后不改变每个DataFrame子对象的index值， 合并之后的DataFrame中index的值0和1重复了两次

![image-20221026141433712](笔记图片/image-20221026141433712.png)

```python
# 如果希望重新设置合并之后的DataFrame对象的index值， 可以添加ignore_index=True参数：
pd.concat([df1, df2], ignore_index=True)
```

![image-20221026145312821](笔记图片/image-20221026145312821.png)

##### b. 两个DataFrame对象的列不完全相同

```python
# 初始化DataFrame对象
df1 = pd.DataFrame([['a', 1], ['b', 2]],
                columns=['letter', 'number'])

df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],
                  columns=['letter', 'number', 'animal'])

display(df1)
display(df3)


# df1中没有animal列， 所以在合并之后的DataFrame对象里， 所对应的元素都被设置成了NaN
```

![image-20221026145408460](笔记图片/image-20221026145408460.png)



```python
# 合并对象
pd.concat([df1, df3], sort=False)  # sort=False : 列的顺序维持原样， 不进行重新排序。
```

![image-20221026150759791](笔记图片/image-20221026150759791.png)

df1中没有animal列， 所以在合并之后的DataFrame对象里， 所对应的元素都被设置成了NaN。

如果只想合并相同的列， 我们可以添加上join='inner'参数：

```python
pd.concat([df1, df3], join='inner')
```

![image-20221026164537553](笔记图片/image-20221026164537553.png)

#### （2）横向合并DataFrame对象

通过设置axis=1, 可以横向合并两个DataFrame对象

```python
# 初始化DataFrame对象
df1 = pd.DataFrame([['a', 1], ['b', 2]],
                columns=['letter', 'number'])

df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],
                  columns=['animal', 'name'])

display(df1)
display(df4)
```

![image-20221026164609918](笔记图片/image-20221026164609918.png)

```python
# 合并对象
pd.concat([df1, df4], axis=1)
```

![image-20221026164640065](笔记图片/image-20221026164640065.png)

### 21. .isin()

#### (1) 直接根据条件进行索引

​	isin()接受一个列表，判断该列中元素是否在列表中。

```python
import numpy as np
import pandas as pd
df=pd.DataFrame(np.random.randn(4,4),columns=['A','B','C','D'])
df
Out[189]: 
          A         B         C         D
0  0.289595  0.202207 -0.850390  0.197016
1  0.403254 -1.287074  0.916361  0.055136
2 -0.359261 -1.266615 -0.733625 -0.790208
3  0.164862 -0.649637  0.716620  1.447703
df['E'] = ['aa', 'bb', 'cc', 'cc']
df
Out[191]: 
          A         B         C         D   E
0  0.289595  0.202207 -0.850390  0.197016  aa
1  0.403254 -1.287074  0.916361  0.055136  bb
2 -0.359261 -1.266615 -0.733625 -0.790208  cc
3  0.164862 -0.649637  0.716620  1.447703  cc
df.E.isin(['aa','cc'])
Out[192]: 
0     True
1    False
2     True
3     True
Name: E, dtype: bool
df[df.E.isin(['aa','cc'])]
Out[193]: 
          A         B         C         D   E
0  0.289595  0.202207 -0.850390  0.197016  aa
2 -0.359261 -1.266615 -0.733625 -0.790208  cc
3  0.164862 -0.649637  0.716620  1.447703  cc

```

#### (2) 根据多条件进行索引

​	此时用&（交集）或者|（并集）进行连接

```python
df[df.E.isin(['aa'])|df.E.isin(['cc'])]
Out[194]: 
          A         B         C         D   E
0  0.289595  0.202207 -0.850390  0.197016  aa
2 -0.359261 -1.266615 -0.733625 -0.790208  cc
3  0.164862 -0.649637  0.716620  1.447703  cc
df[df.E.isin(['aa'])]
Out[195]: 
          A         B        C         D   E
0  0.289595  0.202207 -0.85039  0.197016  aa
```

#### (3) 通过字典的形式传递多个条件

```python
{‘某列’:[条件],‘某列’:[条件],}
```

```python
df['D'] = [1,2,3,4]
df[df.isin({'D':[0,3],'E':['aa','cc']})]
Out[200]: 
    A   B   C    D    E
0 NaN NaN NaN  NaN   aa
1 NaN NaN NaN  NaN  NaN
2 NaN NaN NaN  3.0   cc
3 NaN NaN NaN  NaN   cc

```

#### (4)~相当于is not in

```python
df[~(df.E=='cc')]
Out[202]: 
          A         B         C  D   E
0  0.289595  0.202207 -0.850390  1  aa
1  0.403254 -1.287074  0.916361  2  bb
```

### 22. 列表去空

```python
mytest = [i for i in test if i != '']
```

### 23. value_counts

```
value_counts = df_1['SERVICENAME'].value_counts()
```

![image-20221027162231746](笔记图片/image-20221027162231746.png)

```python
df_rank['排名'].value_counts().rename_axis('排名').reset_index(name='counts')
```

![image-20221027162216343](笔记图片/image-20221027162216343.png)

### 24. apply()

```python
new_df = df[len(df['Title'].split(" "))>=4]
```

```python
# create a new column
df['num_words_title'] = df.apply(lambda x : len(x['Title'].split(" ")),axis=1)
# simple filter on new column
new_df = df[df['num_words_title']>=4]
```

```python
new_df = df[df.apply(lambda x : len(x['Title'].split(" "))>=4,axis=1)]
```

```python
df_merge['Apply_type_count'] = df_merge['Apply_type'].apply(lambda x: len(str(x).split(";")))
```

### 25.部分匹配

str.[contains](https://so.csdn.net/so/search?q=contains&spm=1001.2101.3001.7020)()：包含一个特定的字符串

```python
df[df['name'].str.contains('li')]
```

### 26. 列长度

```python
# 使用pandas的内置方法.str
test['contentLen2'] = test['content'].str.len()
```

```python
df_merge['Apply_type_count'] = df_merge['Apply_type'].apply(lambda x: len(str(x).split(";")))
```

### 27. 输出格式

#### （1）百分号

```python
# 格式化为float，然后处理成%格式： {:.2f}%
print('{:.3f}%'.format(0.234356*100))

# 直接使用参数格式化：{:.2%}
print('{:.2%}'.format(0.234356))

```

`{ }` 的意思是对应`format()`的一个参数，按默认顺序对应，参数序号从0开始，`{0}`对应`format()`的第一个参数，`{1}`对应第二个参数。

### 28. 编码转换

```python
name = "就近办"

print(name) # 就近办
# 字符串转换为字节类型
data = name.encode("utf-8")
print(data) # b'\xe6\xad\xa6\xe6\xb2\x9b\xe9\xbd\x90'

# 把字节转换为字符串
old = data.decode("utf-8")
print(old)
```

### 29. 补充上一行值

```
|  count  | A |  
|---------|---|
|  yes    |2  |
|  yes    |2  |  
|  total  |   |  
|  yes    |2  |  
|  yes    |2  | 
|  total  |   |
```

```python
df.loc[df['count'].eq("total"),"A"] = df['A'].mask(df['A'].eq('')).ffill()
```

```python
print(df)

   count  A
0    yes  2
1    yes  2
2  total  2
3    yes  2
4    yes  2
5  total  2
```

### 30. 取字符串前n位

```python
df["Order_Date"] = df["Shipment ID"].str.extract(r"(\d{8})")
```



### 31. 切片

```python
df1['cityname'] = df1['address_extra'].str.split('/', expand=True)[1]
```



### 29. logger()

## 四、**MySQL**

### **1.判断周几**

```mysql
select if(dayofweek(curdate()) = 1,7,dayofweek(curdate()) -1);
```

### 2. 查询近x天/周/月/季/年

```mysql
# 今天
select * from 表名 where to_days(时间字段名) = to_days(now());

# 昨天
SELECT * FROM 表名 WHERE TO_DAYS( NOW( ) ) - TO_DAYS(时间字段名) <= 1;

#7天
SELECT * FROM 表名 where DATE_SUB(CURDATE(), INTERVAL 7 DAY) <= date(时间字段名);

#近30天
SELECT * FROM 表名 where DATE_SUB(CURDATE(), INTERVAL 30 DAY) <= date(时间字段名);

#本月
SELECT * FROM 表名 WHERE DATE_FORMAT( 时间字段名, '%Y%m' ) = DATE_FORMAT( CURDATE( ) , '%Y%m' );

#上一月
SELECT * FROM 表名 WHERE PERIOD_DIFF( date_format( now( ) , '%Y%m' ) , date_format( 时间字段名, '%Y%m' ) ) =1;

#查询本季度数据
select * from `ht_invoice_information` where QUARTER(create_date)=QUARTER(now());

#查询上季度数据
select * from `ht_invoice_information` where QUARTER(create_date)=QUARTER(DATE_SUB(now(),interval 1 QUARTER));

#查询本年数据
select * from `ht_invoice_information` where YEAR(create_date)=YEAR(NOW());

#查询上年数据
select * from `ht_invoice_information` where year(create_date)=year(date_sub(now(),interval 1 year));

#查询当前这周的数据

SELECT name,submittime FROM enterprise WHERE YEARWEEK(date_format(submittime,'%Y-%m-%d')) = YEARWEEK(now());

#查询上周的数据
SELECT name,submittime FROM enterprise WHERE YEARWEEK(date_format(submittime,'%Y-%m-%d')) = YEARWEEK(now())-1;

#查询当前月份的数据
select name,submittime from enterprise   where date_format(submittime,'%Y-%m')=date_format(now(),'%Y-%m');

#查询距离当前现在6个月的数据

select name,submittime from enterprise where submittime between date_sub(now(),interval 6 month) and now();

#查询上个月的数据
select name,submittime from enterprise   where date_format(submittime,'%Y-%m')=date_format(DATE_SUB(curdate(), INTERVAL 1 MONTH),'%Y-%m');

select * from ` user ` where DATE_FORMAT(pudate, ' %Y%m ' ) = DATE_FORMAT(CURDATE(), ' %Y%m ' ) ;

select * from user where WEEKOFYEAR(FROM_UNIXTIME(pudate,'%y-%m-%d')) = WEEKOFYEAR(now());

select * 
from user 
where MONTH (FROM_UNIXTIME(pudate, ' %y-%m-%d ' )) = MONTH (now());

select * 
from [ user ] 
where YEAR (FROM_UNIXTIME(pudate, ' %y-%m-%d ' )) = YEAR (now())
and MONTH (FROM_UNIXTIME(pudate, ' %y-%m-%d ' )) = MONTH (now());

select * 
from [ user ] 
where pudate between 上月最后一天
and 下月第一天
where   date(regdate)   =   curdate();


select   *   from   test   where   year(regdate)=year(now())   and   month(regdate)=month(now())   and   day(regdate)=day(now());

SELECT date( c_instime ) ,curdate( )
FROM `t_score`
WHERE 1
LIMIT 0 , 30;
```

### 3、建表

```sql
-- y_test.qlt_qlsx definition

CREATE TABLE `qlt_qlsx` (
  `ROWGUID` varchar(50) NOT NULL COMMENT '权力唯一标识',
  `UPDATE_DATE` datetime NOT NULL COMMENT '写入同步时间',
  `UPDATE_TYPE` varchar(1) NOT NULL COMMENT '权力更新类型',
  `QL_KIND` varchar(2) NOT NULL COMMENT '权力事项类型',
  `QL_ATT` varchar(2) DEFAULT NULL COMMENT '权力属性',
  `UNUnifyDo_Other` varchar(1) DEFAULT NULL COMMENT '不接入统一办件库其他原因',
  `IsHasOwnFlow` varchar(2) DEFAULT NULL COMMENT '是否个性化流程（仅用于乡镇延伸事项）',
  `bszn_url` varchar(150) DEFAULT NULL COMMENT '办事指南URL',
  `NoSuit_ReasonDesc` text COMMENT '不适宜网上申报原因描述',
  `business_regulate` text COMMENT '业务审查规范',
  PRIMARY KEY (`tongID`,`ROWGUID`,`UPDATE_DATE`) USING BTREE,
  KEY `tongID_index` (`tongID`) USING BTREE,
  KEY `ROWGUID_index` (`ROWGUID`) USING BTREE,
  KEY `UPDATE_DATE_index` (`UPDATE_DATE`) USING BTREE,
  KEY `qlt_qlsx_index` (`tongID`,`ROWGUID`,`UPDATE_DATE`) USING BTREE,
  KEY `QL_INNER_CODE_index` (`QL_INNER_CODE`) USING BTREE,
  KEY `ql_kind_index` (`QL_KIND`,`QL_MAINITEM_ID`,`QL_SUBITEM_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=COMPRESSED KEY_BLOCK_SIZE=8 COMMENT='权力信息发布表';
```



## 五、**Linux**

### 1. 查看行号

```shell
set nu

set number
```

### 2. 搜索关键字

vim工具

```markdown
1、进入vi中，编辑模式中先按下键盘上"esc"跳转成命令输入模式

2、输入斜杠"/"，这时屏幕会跳转到底部，输入栏出现"/"

3、输入你需要查找的关键字，回车键

4、如果要继续查找下一个关键字，输入n

5、查找上一个关键字，输入N（大写）

```

### 3. top

```ssh
%us：表示用户空间程序的cpu使用率（没有通过nice调度）

%sy：表示系统空间的cpu使用率，主要是内核程序。

%ni：表示用户空间且通过nice调度过的程序的cpu使用率。

%id：空闲cpu

%wa：cpu运行时在等待io的时间

%hi：cpu处理硬中断的数量

%si：cpu处理软中断的数量

%st：被虚拟机偷走的cpu
```

### 4. 内核

```shell
cat /etc/issue （简单）

cat /etc/lsb-release（具体）

uname -a（内核）

sudo uapdate-grub
**硬盘信息
cat /sys/block/sda/device/model
```



## 六、windows

### 1. 查看文件前几行

在Window10的[PowerShell](https://so.csdn.net/so/search?q=PowerShell&spm=1001.2101.3001.7020)里，使用 type XXX|Select -First n 表示查找XXX文件的前n条记录，而 type XXX|Select -Last n 表示查找XXX文件的最后n条记录。

#### （1）统计的文件的总行数

```markdown
cmd
find /V "" /C FileList.txt
```

![img](https://img-blog.csdnimg.cn/20210710111740242.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NhbnFpbWE=,size_16,color_FFFFFF,t_70)

#### (2)查看文件的前10行

```markdown
powershell
type FileList.txt|Select -First 10
```

![img](https://img-blog.csdnimg.cn/20210710111255924.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NhbnFpbWE=,size_16,color_FFFFFF,t_70)

#### (3)查看文件的最后10行

```markdown
powershell
type FileList.txt|Select -Last 10
```

![img](https://img-blog.csdnimg.cn/20210710111301572.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NhbnFpbWE=,size_16,color_FFFFFF,t_70)

## 七、ERROR

1. AssertionError: 3 columns passed, passed data had 4 columns

```markdown
使用pandas.DataFrame构造函数时每个子列表被解释为一行的事实
```

2. AttributeError: ‘NoneType‘ object has no attribute ‘reset_index‘

```python
# 原始
df.sort_values(['datatime'],inplace=True).reset_index(drop=True）
```

```python
# 修改后
df.sort_values(['datatime'],inplace=True)
df.reset_index(drop=True，inplace=True）
```

3. not all arguments converted during string formatting,not all arguments converted during string formatting

检查mysql “%s”数量是否对应；检查功能函数返回值的字段数是否对应

4. pandas筛选报错ValueError: Cannot mask with non-boolean array containing NA / NaN values

```python
df = df.loc[df["列名"].str.contains("需要筛选的字符串"),:]
```

```python
#解决方案是：在筛选中加上"na=False"，这意思是：遇到非字符串的情况，直接忽略
df = df.loc[df["列名"].str.contains("需要筛选的字符串", na=False),:]
```

5.ValueError: The truth value of a [Series](https://so.csdn.net/so/search?q=Series&spm=1001.2101.3001.7020) is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().

```
出现此错误是因为Python的逻辑运算符(and、or、not)是用来与布尔值（boolean）一起使用的，所以当试图将它们与序列或数组一起使用时，系统程序不清楚如何确定它是真的还是假的，因此会导致ValueError。
```



## 八、XML转JSON

```python
#	将python对象编码成Json字符串
#   json库dumps()是将dict转化成json格式,loads()是将json转化成dict格式。
#   dumps()方法的ident=1,格式化json
parser_data = xmltodict.parse(xml_file)
json_conversion = json.dumps(parser_data, indent=4, ensure_ascii=False)
json_conversion = json_conversion.replace("null", "''")
```

## 九、数学符号

```markdown
Α α：阿尔法 Alpha。

Β β：贝塔 Beta。

Γ γ：伽玛 Gamma。

Δ δ：德尔塔 Delte 。

Ε ε：艾普西龙 Epsilon。

Ζ ζ  ：捷塔 Zeta。

Ε η：依塔 Eta。

Θ θ：西塔 Theta。

Ι ι：艾欧塔 Iota。

Κ κ：喀帕 Kappa。

∧ λ：拉姆达 Lambda。

Μ μ：缪 Mu。

Ν ν：拗 Nu。

Ξ ξ：克西 Xi。

Ο ο：欧麦克轮 Omicron。

∏ π：派 Pi。

Ρ ρ：柔 Rho。

∑ σ：西格玛 Sigma。

Τ τ：套 Tau。

Υ υ：宇普西龙 Upsilon。

Φ φ：fai Phi。

Χ χ：器 Chi。

Ψ ψ：普赛 Psi。

Ω ω：欧米伽 Omega。
```

## 十、深度学习

#### 1. conda

```python
python -m pip install --upgrade pip
python -m pip install --upgrade setuptools
```

```python
conda list 查看安装了哪些包
conda info --envs
conda env list 或 conda info -e 查看当前存在哪些虚拟环境
conda update conda 检查更新当前conda
conda create -n your_env_name python=X.X（2.7、3.6等)命令创建python版本为X.X、名字
conda remove -n your_env_name(虚拟环境名称) --all删除环境
conda remove --name your_env_name  package_name删除某个包

conda install python=版本号 # 更改当前环境的python版本

```

```shell
sudo rm /var/lib/dpkg/lock 解锁
sudo rm /var/lib/apt/lists/lock
```

```python
conda 添加镜像
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/

conda config --set show_channel_urls yes

查看全部的镜像：
conda config --show channels

移除想移除的镜像：
conda config --remove channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/
```

#### 2. doccnao

https://blog.csdn.net/WASEFADG/article/details/124536722

```python
pip install doccano -i https://pypi.tuna.tsinghua.edu.cn/simple/
```

```python
# 初始化数据库
doccano init
 
# 创建一个super user。这里要把pass改成你需要的密码。当然，用户名也可以改成别的。
doccano createuser --username admin --password password
```

```python
# 启动webserver
doccano webserver --port 8000
```

```python
# 启动任务队列
doccano task
```

```
打开浏览器（最好是Chrome），在地址栏中输入http://127.0.0.1:8000/并回车。
```

```python
# 多人标注：设置用户名= admin,密码=pass
 
doccano createuser --username user1 --password 123456
```

#### 3. 模型训练

![image-20221206103612747](笔记图片/image-20221206103612747.png)



![image-20221206154516691](笔记图片/image-20221206154516691.png)



#### **ERROR**

1.  问题：“You will need to adjust your conda configuration to proceed”

```
解决:删除已经设定好滴默认镜像源,执行后就恢复了原来的源
conda config --remove-key channels
```



## 十一、PyCharm

代码编辑快捷键

|      |      |      |
| ---- | ---- | ---- |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |


2、搜索/替换快捷键
序号	快捷键	作用
1	CTRL+F	查找
2	F3	查找下一个
3	SHIFT+F3	查找上一个
4	CTRL+R	替换
5	CTRL+SHIFT+F	指定路径下查找
6	CTRL+SHIFT+R	指定路径下替换
3、代码运行快捷键
序号	快捷键	作用
1	ALT+SHIFT+F10	选择程序文件并运行代码
2	ALT+SHIFT+F9	选择程序文件并调试代码
3	SHIFT+F10	运行代码
4	SHIFT+F9	调试代码
5	CTRL+SHIFT+F10	运行当前编辑区的程序文件
4、代码调试快捷键
序号	快捷键	作用
1	F8	单步
2	F7	单步（无函数时同F8）
3	SHIFT+F8	单步跳出
4	ALT+F9	运行到光标所在位置处
5	ALT+F8	测试语句
6	F9	重新运行程序
7	CTRL+F8	切换断点
8	CTRL+F8	查看断点
5、应用搜索快捷键
序号	快捷键	作用
1	ALT+F7	查找应用
2	CTRL+F7	在文件中查找应用
3	CTRL+SHIFT+F7	在文件中高亮应用
4	CTRL+ALT+F7	显示应用
6、代码重构快捷键
序号	快捷键	作用
1	F5	复制文件
2	F6	移动文件
3	SHIFT+F6	重命名
4	ALT+DELETE	安全删除
5	CTRL+F6	改变函数形式参数
6	CTRL+ALT+M	将代码提取为函数
7	CTRL+ALT+V	将代码提取为变量
8	CTRL+ALT+C	将代码提取为常数
9	CTRL+ALT+F	将代码提取为字段
10	CTRL+ALT+P	将代码提取为参数
7、动态模块快捷键
序号	快捷键	作用
1	CTRL+ALT+J	使用动态模板包裹
2	CTRL+J	插入动态模板
8、导航快捷键
序号	快捷键	作用
1	CTRL+N	进入类
2	CTRL+SHIFT+N	进入文件
3	CTRL+ALT+SHIFT+N	进入符号
4	CTRL+←←	进入上一个编辑位置
5	CTRL+→→	进入下一个编辑位置
6	CTRL+→→	进入下一个编辑位置
7	SHIFT+ESC	隐藏活动/最后活动的窗口
8	CTRL+SHIFT+F4	关闭活动的运行/消息/查找等窗口
9	CTRL+G	显示光标所在行与列
10	CTRL+E	弹出最近打开的文件
11	CTRL+ALT+←/→←/→	向前/向后导航
12	CTRL+SHIFT+BACKSPACE	导航到最后编辑的位置
13	CTRL+B	跳转到声明部分
14	CTRL+CLICK(鼠标左键)	跳转到声明部分
15	CTRL+ALT+B	跳转到代码实施部分
16	CTRL+SHIFT+I	打开快速定义查找
16	CTRL+SHIFT+B	跳转到类型说明
17	CTRL+U	跳转超类/方法
18	CTRL+↑↑	跳转到上一个方法
19	CTRL+↓↓	跳转到下一个方法
20	CTRL+[	跳转到代码块的开头
21	CTRL+]	跳转到代码块的结尾
22	CTRL+F12	弹出文件结构
23	CTRL+H	弹出类层次结构
24	CTRL+SHIFT+H	弹出方法层次结构
25	CTRL+ALT+H	弹出调用层次结构
26	F2/SHIFT+F2	下一个/上一个错误
27	F4	查看源代码
28	ALT+HOME	显示导航栏
29	F2/SHIFT+F2	下一个/上一个错误
30	F11	增加书签
31	CTRL+F11	增加数字/字母书签
32	CTRL+SHIFT+[1-9]	增加数字书签
33	SHIFT+F11	显示书签
9、通用快捷键
序号	快捷键	作用
1	ALT+[0-9]	打开相应的工具窗口
2	CTRL+ALT+Y	同步
3	CTRL+SHIFT+F12	最大化编辑器
4	ALT+SHIFT+F	添加到收藏夹
5	ALT+SHIFT+I	使用当前配置文件检查当前文件
6	CTRL+ALT+S	快速出现设置对话框
7	CTRL+SHIFT+A	查找并调试编辑器的功能
8	ALT+TAB	在选项卡和工具窗口之间切换

## 十二、正则表达式

Road To Coding:

https://www.r2coding.com/#/README?id=%e5%9f%ba%e7%a1%80%e6%ad%a3%e5%88%99%e8%a1%a8%e8%be%be%e5%bc%8f%e9%80%9f%e6%9f%a5%e8%a1%a8

## 乱言乱语

```
复方氨酚那敏颗粒：对乙酰氨基酚、咖啡因、马来酸氯苯那敏和人工牛黄。
功效：适用于缓解普通感冒及流行性感冒引起的发热、头痛、四肢酸痛、打喷嚏、流鼻涕、鼻塞、咽痛等症状

感康：对乙酰氨基酚、盐酸金刚烷胺、人工牛黄、马来酸氯苯那敏等。
功效：
1、酰氨基酚：具有解热镇痛作用，可治疗感冒、发热、肌肉酸痛等。 
2、盐酸金刚烷胺：具有抗病毒作用。 
3、人工牛黄：具有解热、抗惊厥作用。 
4、马来酸氯苯那敏：具有抗过敏作用，可缓解感冒时流鼻涕、打喷嚏、流泪等过敏反应。

感冒清热颗粒：薄荷，防风，柴胡，紫苏，葛根，苦杏仁，白芷，苦地丁，芦根等。
功效：感冒清热颗粒具有疏散，风寒表清热，用于风寒感冒，头痛发热，鼻流清涕，咳嗽咽干等病症的治疗。

蓝芩口服液：板蓝根、黄芩、栀子、黄柏、胖大海。
功效：急性咽炎、肺胃实热症所致的咽痛、咽干、咽部灼热。

999感冒灵：主成分包括有三叉苦、岗梅、金盏银盘、薄荷油、野菊花等中成药，还包含一些西药有马来酸氯苯那敏、咖啡因、对乙酰氨基酚等,辅料是蔗糖粉。
功效：解热镇痛，可以用于感冒引起的头痛、鼻塞、流涕、咽痛等症状



```



## **Q&A**



### **金华项目**

#### 20221129-就近办、窗口

```markdown
1. 区分办件所在地： 区县、乡镇、村社--确认办理地点
2. 政银合租网点办件量--数据
3. 办件量->事项数、办件量占比->事项数占比

接件量：办件受理表（dsc_jh_ads_share_pre_accept_s_h）
```

#### 20221212-就近办（方案更新、脑图、代码）

```markdown
 1. line63、事项下沉度
 2. 行政区划表关联
```



### 政策要素识别

#### 20221209-苏商通要素识别

```markdown
Q: 富文本转纯文本

1. 项目实际数据格式，数据如何获取，如何存储的,当前的富文本包含什么内容
2. 项目上可以怎么转，能转到什么程度
	字符串替换、正则表达式
3. 是否要中研院重新训练（只影响需要分类的字段）


标版，代码项映射
```

#### 
