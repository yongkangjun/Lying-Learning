

# **躺平小笔记**

```python
# -*- coding:utf-8 -*-
"""
Description:
@author: Yaoyk
@date: 2022-06-12
"""
```

```markdown
Better late than never.Late is better than not to come.
迟做总比不做好；晚来总比不来强。
Bu duan ti sheng ji lei cai shi jie jing,zi ji de cai shi kao pu de.
不断提升积累才是捷径，自己的才是靠谱的。
A man needs to lie flat, but not to rot.
人需要躺平，但不是摆烂。
```



## 一、**算法**

### 1. **二分查找**

- 思想:取一个索引开头left,取一个索引末尾(len(队列)-1)right,让你的值跟(left + right)//2(middle)比。如果索引middle值比你查的值大,把middle赋值给right,反之把middle赋值给left。

**（1）该数组，必须是有序：**

1. 二分查找依赖的是**顺序表结构**，即**数组**。
2. 二分查找针对的是有序数据，因此只能用在插入、删除操作不频繁，一次排序多次查找的场景中。

**（2）对数据量大小有要求**：

1. 数据量太小不适合二分查找，与直接遍历相比效率提升不明显。但有一个例外，就是数据之间的比较操作非常费时，比如数组中存储的都是组成长度超过100的字符串。
2. 数据量太大也不适合用二分查找，因为数组需要连续的空间，若数据量太大，往往找不到存储如此大规模数据的连续内存空间。

**（3）一般要求找到的是某一个值或一个位置**

### 2. 孤立森林

孤立森林官方接口：https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html#sklearn.ensemble.IsolationForest



**基本用法：**

```python
sklearn.ensemble.IsolationForest(
              *, 
              n_estimators=100, 
              max_samples='auto', 
              contamination='auto', 
              max_features=1.0, 
              bootstrap=False, 
              n_jobs=None, 
              random_state=None, 
              verbose=0, 
              warm_start=False)
```

**参数详解：**

```python
n_estimators : int, optional (default=100)

iTree的个数，指定该森林中生成的随机树数量，默认为100个

max_samples : int or float, optional (default=”auto”)

构建子树的样本数，整数为个数，小数为占全集的比例，用来训练随机数的样本数量，即子采样的大小

如果设置的是一个int常数，那么就会从总样本X拉取max_samples个样本来生成一棵树iTree

如果设置的是一个float浮点数，那么就会从总样本X拉取max_samples * X.shape[0]个样本,X.shape[0]表示总样本个数

如果设置的是"auto"，则max_samples=min(256, n_samples)，n_samples即总样本的数量

如果max_samples值比提供的总样本数量还大的话，所有的样本都会用来构造数，意思就是没有采样了，构造的n_estimators棵iTree使用的样本都是一样的，即所有的样本

contamination : float in (0., 0.5), optional (default=0.1)

取值范围为(0., 0.5),表示异常数据占给定的数据集的比例，数据集中污染的数量，其实就是训练数据中异常数据的数量，比如数据集异常数据的比例。定义该参数值的作用是在决策函数中定义阈值。如果设置为'auto'，则决策函数的阈值就和论文中定义的一样

max_features : int or float, optional (default=1.0)

构建每个子树的特征数，整数位个数，小数为占全特征的比例，指定从总样本X中抽取来训练每棵树iTree的属性的数量，默认只使用一个属性

如果设置为int整数，则抽取max_features个属性

如果是float浮点数，则抽取max_features * X.shape[1]个属性

bootstrap : boolean, optional (default=False)
采样是有放回还是无放回，如果为True，则各个树可放回地对训练数据进行采样。如果为False，则执行不放回的采样。

n_jobs :int or None, optional (default=None)
在运行fit()和predict()函数时并行运行的作业数量。除了在joblib.parallel_backend上下文的情况下，None表示为1。设置为-1则表示使用所有可用的处理器

random_state : int, RandomState instance or None, optional (default=None)

每次训练的随机性

如果设置为int常数，则该random_state参数值是用于随机数生成器的种子

如果设置为RandomState实例，则该random_state就是一个随机数生成器

如果设置为None，该随机数生成器就是使用在np.random中的RandomState实例

verbose : int, optional (default=0)

训练中打印日志的详细程度，数值越大越详细

warm_start : bool, optional (default=False)
当设置为True时，重用上一次调用的结果去fit,添加更多的树到上一次的森林1集合中；否则就fit一整个新的森林

3、属性
base_estimator_：The child estimator template used to create the collection of fitted sub-estimators.

estimators_：list of ExtraTreeRegressor instances The collection of fitted sub-estimators.

estimators_：features_list of ndarray The subset of drawn features for each base estimator.

estimators_samples_：list of ndarray The subset of drawn samples for each base estimator.

max_samples_：The actual number of samples

n_features_：DEPRECATED: Attribute n_features_ was deprecated in version 1.0 and will be removed in 1.2.

n_features_in_：Number of features seen during fit.

feature_names_in_：Names of features seen during fit. Defined only when X has feature names that are all strings

4、方 法
fit(X[, y, sample_weight])：训练模型

decision_function(X)：返回平均异常分数

predict(X)：预测模型返回1或者-1

fit_predict(X[, y])：训练-预测模型一起完成

get_params([deep])：Get parameters for this estimator.

score_samples(X)：Opposite of the anomaly score defined in the original paper.

set_params(**params)：Set the parameters of this estimator.

```

**算法实现：**

```python
# -*- coding: utf-8 -*-

# 加载模型所需要的的包
import pandas  as pd
from sklearn.ensemble import IsolationForest
import warnings
warnings.filterwarnings('ignore')


# 构造一个数据集，只包含一列数据，假如都是月薪数据，有些可能是错的
df = pd.DataFrame({'salary':[4,1,4,5,3,6,2,5,6,2,5,7,1,8,12,33,4,7,6,7,8,55]})


# 构建模型 ,n_estimators=100 ,构建100颗树
model = IsolationForest(n_estimators=100,
                      max_samples='auto',
                      contamination=float(0.1),
                      max_features=1.0)
# 训练模型
model.fit(df[['salary']])

# 预测 decision_function 可以得出 异常评分
df['scores']  = model.decision_function(df[['salary']])

#  predict() 函数 可以得到模型是否异常的判断，-1为异常，1为正常
df['anomaly'] = model.predict(df[['salary']])
print(df)

```

### 3. 分类

### 4. 优化

![image-20230208164154247](笔记图片/image-20230208164154247.png)

![image-20230208164204598](笔记图片/image-20230208164204598.png)



## 二、Jupyter快捷操作



|   Markdown    |         功能          |
| :-----------: | :-------------------: |
|      m/y      |      切换状态栏       |
|     -空格     |       无序列表        |
|    1.空格     |       有序列表        |
| ```python ``` |    插入python代码     |
|  **代码块**   |       **功能**        |
|      dd       |      删除单元格       |
|   L/shift+L   | 切换行号/切换所有行号 |
|    shift+m    |      合并单元格       |
| ctrl+shift+-  |      拆分单元格       |
|      a/b      |      插入单元格       |

### 1. Jupyter Notebook有两种mode

- Enter：进入edit模式
- Esc：进入command模式

### 2. Command命令快捷键：

- A：在上方增加一个cell
- B：在下方增加一个cell
- X：剪切该cell
- C：复制该cell
- V：在该cell下方粘贴复制的cell
- Shift-V：在该cell上方粘贴复制的cell
- L：隐藏、显示当前cell的代码行号
- shift-L：隐藏/显示所有cell的代码行号
- O：隐藏该cell的output
- DD：删除这个cell
- Z：撤销删除操作
- Y：转为code模式
- M：转为markdown模式
- R：转为raw模式
- H：展示快捷键帮助
- Shift-Enter：运行本单元，选中下个单元 新单元默认为command模式
- Ctrl-Enter 运行本单元
- Alt-Enter 运行本单元，在其下插入新单元 新单元默认为edit模式
- OO：重启当前kernal
- II：打断当前kernal的运行
- shift+上/下：向上/下选中多个代码块
- 上/下：向上/下选中代码块
- F：查找替换

### 3. Edit命令快捷键：

- Tab：代码补全
- ctrl]或Tab：缩进（向右）
- ctrl[或shift-Tab：反缩进（向左）
- ctrl A：全选
- ctrl D：删除整行
- ctrl Z：撤销





## 三、**Python** Q&A

```markdown
# 注意：建议在元组的最后多加一个逗号，用于标识他是一个元组。
```

```markdown
# 下划线
# 在for循环语句之中会使用一个标识符来表示每次迭代从序列内取到的元素，当使用下划线_作为迭代元素标识符时，就意味着在这一个循环结构之中不会使用到迭代元素了
# 下划线作为一个变量来表示的时候意思就是哑元变量，约定俗成的编程习惯和语法为开发者不会去使用哑元变量，或者它只是作为临时变量存在。虽然也可以视为一般变量，但是这样就不符合python命名规则了，所以用下划线作为变量名时它就是有着特殊意义的
for _ in range(2):
	print("hello")



# 下划线变量名还有一个使用场景就是在python交互模式内使用
b=0
b
0
_
0

从代码之中可以看出变量b的值为了0，当调用它的时候就会将0这个值给打印出来。但是再调用变量名为下划线的变量时却也将0这个值给打印出来了，这就是下划线变量名在python交互模式中的作用，保存最后一个表达式的结果
```



### **1. Pandas→mysql**

```markdown
Q: Pandas to Mysql AttributeError: ‘Timestamp‘ object has no attribute ‘translate‘
```

```python
rst['ds'] = rst['ds'].apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S'))

warn_day_hour['date_day'] = warn_day_hour['date_day'].astype(str)
```



### **2. pandas高级接口--时间(.dt)**

```python
dt.year

dt.month

dt.day

dt.hour

dt.minute

dt.second

dt.week

# (dt.weekofyear和dt.week一样)分别返回日期的年、月、日、小时、分、秒及一年中的第几周
```



### **3. 提取每小时，切片**

```python
for m in range(6,24):
    a=0
    for i in range(len(df)):
        if int(df.iloc[i]['计划时间']**[:2])** == m:
            a+=df.iloc[i]['承载人数']
    print(a)
```



### **4. 去重**

#### （1）去除完全重复的行数据

```python
data.drop_duplicates(inplace=True)
```

#### （2）去除某几列重复的行数据

```python
data.drop_duplicates(subset=['A','B'],keep='first',inplace=True)
```

**subset：** 列名，可选，默认为None

**keep：** {‘first’, ‘last’, False}, 默认值 ‘first’

**first：** 保留第一次出现的重复行，删除后面的重复行。

**last：** 删除重复项，除了最后一次出现。

**False：** 删除所有重复项。

**inplace：**布尔值，默认为False，是否直接在原数据上删除重复项或删除重复项后返回副本。（inplace=True表示直接在原来的DataFrame上删除重复项，而默认值False表示生成一个副本。）

#### （3）去除重复列

```python
df_merge_out_plan_tmp = df_merge_out_plan_tmp.T.drop_duplicates().T
```

#### （4）python去重

​	转换为集合set(),去除去除重复值。

​	集合的元素只能是 int、bool、str、tuple 。

### **5. 表关联**

（1）多表

```python
# 4表关联, projid
df_merge = reduce(lambda x, y: pd.merge(x, y, on=['PROJID']), [df_1, df_2, df_3, df_4])  # PROJID*4表
```

（2）两表

```python
df_merge1 = pd.merge(df_1, df_2, how='inner', on='key')

df_merge = pd.merge(dfl,df2,left_on='key',right_on='key) # 左右字段不一样

pd.merge(df_1,df_2,on=['id','subject_id'])
```



### **6. 删除指定列**

```python
df = df.drop(columns=['date', 'month'])
```

```python
df.drop(df.index[0], inplace=True)    # 删除第1行
df.drop(df.index[0:3], inplace=True)   # 删除前3行
df.drop(df.index[[0, 2]], inplace=True) # 删除第1第3行
```



### **7. 删除空值行**、列

（1）

```python
df_approve_out = df_approve_out[~(df_approve_out['anomaly_style'].isnull())] #删掉空行

df = df.dropna(axis=0)  # 删除有空值的行，使用参数axis=0

df = df.dropna(axis=1) #删除有空值的列，使用参数axis=1
```

（2）

```python
# 删除anomaly_style空值行

unique_anomaly_style = df_approve_out['anomaly_style'].astype(str).unique()

unique_anomaly_style = [i for i in unique_anomaly_style if i != '']

df_approve_out = df_approve_out[df_approve_out['anomaly_style'].isin(unique_anomaly_style)]

df = df.dropna(subset=['name','team'])
```



### **8. 排序**

#### (1)pandas

inplace：是否修改原始DataFrame

当 **inplace = False** 时，返回为修改过的数据，原数据不变。

当 **inplace = True** 时，返回值为 None，直接在原数据上进行操作。



升：

```python
df.sort_values(by='price', inplace=True)
```

降：

```python
df.sort_values(by='price', inplace=True, ascending=False)
```

```python
data.sort_values(by='AdmissionDate')    # 日期升序
```

```python
# python>>>>>>>>>>>>>>

# sort的参数reverse 可以控制排序规则，reverse为True 时是降序， reverse为False时是升序（默认），运行如图所示的程序，进行升序排序。

a.sort(reverse=False)
```

记得重置索引

```python
df = df.reset_index(drop=True)
```

#### (2) python->list

```python
# list.sort()方法
# iterable.sort(self,key,reverse)
# iterable以为可迭代对象，可以是列表、集合、字典
# key是函数，指定取待排序元素的函数规则

reverse实现降序排序，需要提供一个bool值，默认为False（升序）

L=[8,2,50,3]
L.sort()
print(L)
```

```python
# sorted()函数
# sorted(iterable,key=None,reverse=False)
# key:通过这个参数可以自定义排序逻辑

L=[8,2,50,3]
l=sorted(L)
print(l)
```



### **9. dataframe为空**

```python
if not df.empty:

# 如果df为空，则 df.empty 返回 True，反之 返回False。

rst = rst.where(rst.notnull(), None)      # 若dataframe有空值，则转换为None写入
```



### **10. 重新索引**

```python
# 不保留原来的索引，drop=True
df.reset_index(drop=True)
# 原始数据中某些列有None，报错，加inplace=True
df.reset_index(drop=True, inplace=True)
```



### **11. 时间**

#### （1）时间转换

```python
df['日期'] = pd.to_datetime(df['日期'], format='%Y-%m-%d')  #转化为时间格式

df['date'] = df['date'].dt.date
```

#### （2）当前时间

```python
import time
today = time.strftime("%Y-%m-%d")
# 2021-05-02
```



```python
import pandas as pd
pd.to_datetime('today').isoformat()
# '2019-04-18T04:03:32.493337'

# Or, `strftime` for custom formats.
pd.to_datetime('today').strftime('%Y-%m-%d')
# '2019-03-27'
```

```python
## 时间-python

from datetime import datetime
#将日期定义为字符串    
date_str1 = 'Wednesday, July 18, 2020' 
date_str2 = '18/7/20' 
date_str3 = '18-07-2020'  
#将日期转化为datetime对象 
dmy_dt1 = datetime.strptime(date_str1, '%A,%B%d,%Y') 
dmy_dt2 = datetime.strptime(date_str2, '%d/%m/%y') 
dmy_dt3 = datetime.strptime(date_str3, '%d-%m-%Y')  
#处理为相同格式，并打印输出
print(dmy_dt1) 
print(dmy_dt2) 
print(dmy_dt3) 
```



#### （3）获取下周几

```python
from datetime import datetime, timedelta


def next_weekday(weekday, d=datetime.now()):
    """获取下周几日期

    :param weekday: weekday取值1-7
    :param d: 原日期，默认当前时间
    :return: datetime.datetime
    """
    delta = weekday - d.isoweekday()
    if delta <= 0:
        delta += 7
    return d + timedelta(delta)


print(next_weekday(weekday=1))  # 下周一
print(next_weekday(weekday=3, d=datetime(2020, 1, 1)))  # 2020.1.1的下周三（这个日期是周三）
```



### **12. 保留两位**小数

```python
df_merge = df_merge.round({'wait_time': 2}) # 保留两位

df_merge = round(df_merge['wait_time'], 2) # 保留两位
```



### **13. 获取周几**

```python
df = pd.DataFrame(pd.date_range(start='2020-05-01', end='2020-06-05'))

df[1] = df[0].dt.dayofweek + 1

df.head(10)

#########################
# dt的其他常用属性和方法如下：

df['日期'].dt.day   # 提取日期

df['日期'].dt.year # 提取年份

df['日期'].dt.hour # 提取小时

df['日期'].dt.minute # 提取分钟

df['日期'].dt.second # 提取秒

df['日期'].dt.week # 一年中的第几周

df['日期'].dt.weekday # **返回一周中的星期几，0代表星期一，6代表星期天**

df['日期'].dt.dayofyear # 返回一年的第几天

df['日期'].dt.quarter # 得到每个日期分别是第几个季度。

df['日期'].dt.is_month_start # 判断日期是否是每月的第一天

df['日期'].dt.is_month_end # 判断日期是否是每月的最后一天

df['日期'].dt.is_leap_year # 判断是否是闰年

df['日期'].dt.month_name() # 返回月份的英文名称

df['日期'].dt.to_period('Q') # M 表示月份，Q 表示季度，A 表示年度，D 表示按天

df['日期'].dt.weekday_name # 返回星期几的英文 由于pandas版本问题，改变pandas版本在cmd中输入：pip install --upgrade pandas==0.25.3

Series.dt.normalize() # 函数将给定系列对象中的时间转换为午夜。
```

**示例**：

```python
import pandas as pd
# Thepandas.Periodrepresents a period of time

# creating two Period objects

period1 = pd.Period("2023-01-30")

period2 = pd.Period(freq ='D', year = 2021, month = 9, day = 22, hour = 4, minute = 55)

# display the Period objects

print("Period1...\n", period1)

print("Period2...\n", period2)

# get the day of week from two Period objects

res1 = period1.dayofweek + 1

res2 = period2.dayofweek

# Return the day of the week from the two Period objects

# Results shows Monday=0, Tuesday=1, ... ,Sunday=6

print("\nDay of the week from the 1st Period object ...\n", res1)

print("\nDay of the week from the 2nd Period object...\n", res2)
```

```python
today_date = pd.to_datetime("today").strftime("%Y-%m-%d")
today_date = pd.Period(today_date)
today_week = today_date.dayofweek + 1
```



### **14. pop删除函数**

```python
popped_num = t1.pop(0)   

#pop()函数，从列表取出第0个元素将其存储在popped_num，并删除
```



### **15. 空值赋0**

```python
mydf['列名']=mydf['列名'].fillna(0)
```

python中，如何初始化不同的变量类型为空值

| 变量类型 |  空值   |
| :------: | :-----: |
|  字符串  |   “ ”   |
|   数值   | 0或None |
|   列表   |   []    |
|   字典   |   {}    |
|   元组   |   ()    |



```python
# 遇到None

df.isnull() # 查找
```



### 16. 列重命名

#### (1) 部分列重命名

```python
# 部分列重命名
# 没有指定inplace=True， df本身的列名并没有改变。
df.rename(columns={'a': 'A'})
# 原数据会改变
df.rename(columns={'a': 'A'}, inplace=True)
# 通过赋值对新数据列改名
df2 = df.rename(columns={'a': 'A'})
```

#### (2) 全部列重命名

```python
# 全部列重命名，直接改变了原始数据
df.columns = ['a1', 'b1', 'c1', 'd1']
```

#### (3) str 批量修改列名

```python
# str 批量修改列名
df.columns = df.columns.str.replace('1', '2')
```

### 17.1 取整(python)

#### （1）向下取整

向下取整直接用内建的 `int()` 函数即可：

```python
>>> a = 3.75
>>> int(a)
3
```

#### （2）四舍五入

对数字进行四舍五入用 `round()` 函数：

```python
>>> round(3.25); round(4.85)
3.0
5.0
```

#### （3）向上取整

向上取整需要用到 `math` 模块中的 `ceil()` 方法:

```python
>>> import math
>>> math.ceil(3.25)
4.0
>>> math.ceil(3.75)
4.0
>>> math.ceil(4.85)
5.0
```

#### （4）分别取整数部分和小数部分

有时候我们可能需要分别获取整数部分和小数部分，这时可以用 `math` 模块中的 `modf()` 方法，该方法返回一个包含小数部分和整数部分的元组：

```python
>>> import math
>>> math.modf(3.25)
(0.25, 3.0)
>>> math.modf(3.75)
(0.75, 3.0)
>>> math.modf(4.2)
(0.20000000000000018, 4.0)
```

### 17.2 取整(pandas)

#### (1)将数值四舍五入到N位小数

```python
df['a'].round(N)
```

#### (2)向上舍入

```python
np.ceil(df['a'])

df['a'].apply(np.ceil)
```

#### (3)向下舍入

```python
df['a'].apply(np.floor)
```

#### (4)四舍五入到最接近的千位数

```python
# pandas round()方法实际上允许输入负数。负输入指定小数点左侧的位置数。例如：
# 四舍五入（小数=-1）：四舍五入到最接近的十
# 四舍五入（小数=-2）：四舍五入到最接近的百位数

# 要四舍五入到最接近的千位数，只需设置decimals=-3
df['a'].round(-3)
```

#### (5)用不同的条件对数据框架进行取整

```python
# round()方法中的decimals参数可以是整数值，也可以是字典。这使得同时对多个列进行取整变得容易。

# 可以将第一列四舍五入到2位小数，并将第二列四舍五入到最接近的千位

df.round({'a':2, 'b':-3})
```

### 18. 输出excel

#### (1) 输出单个sheet

```python
import pandas as pd
 
df = pd.DataFrame({
    '销量': [10, 20],
    '售价': [100.123, None],
}, index=['aaa', 'bbb'])
df.index.name = '货号'
df.to_excel('tb.xlsx',            # 路径和文件名
            sheet_name='tb1',     # sheet 的名字
            float_format='%.2f',  # 保留两位小数
            na_rep='我是空值')     # 空值的显示
```

#### (2)不输出 index

```python
df.to_excel('tb.xlsx', index=False)
```

#### (3)输出多个sheet, 并设置输出的日期格式 (不输出时分秒)

```python
import pandas as pd
from datetime import datetime
 
df1 = pd.DataFrame(
    {'日期': [datetime(2020, 1, 1), datetime(2020, 1, 2)],
     '销量': [10, 20]}
)
 
df2 = pd.DataFrame(
    {'日期': [datetime(2020, 2, 1), datetime(2020, 2, 2)],
     '销量': [15, 25]}
)
 
with pd.ExcelWriter(
    'tb.xlsx',
    datetime_format='YYYY-MM-DD'  # 只显示年月日, 不显示时分秒
) as writer:
    df1.to_excel(writer, sheet_name='1月')  # Sheet1
    df2.to_excel(writer, sheet_name='2月')  # Sheet2
```

### 19. 分组

(1)求平均

```python
df_time_servicet = df_tmp_servicet.groupby(['DSC_CITY', 'DSC_ADM_REGION', 'HANDER_DEPTNAME', 'SERVICENAME', 'banjie_month', 'INFOTYPE'], as_index=False)['time_limit'].mean()
```

(2)统计

```python
df_node_num_region = df_node_tmp_region.groupby(['PROJID', 'DSC_CITY', 'DSC_ADM_REGION', 'banjie_month'], as_index=False)['NODE_NAME'].count()
```

```markdown
by：用于确定 groupby 的组。 如果 by 是一个函数，它会在对象索引的每个值上调用。 如果传递了 dict 或 Series，则 Series 或 dict VALUES 将用于确定组（Series 的值首先对齐；参见 .align() 方法）。 如果传递了长度等于所选轴的列表或 ndarray，则按原样使用这些值来确定组。 一个标签或标签列表可以通过 self 中的列传递给 group。 请注意，元组被解释为（单个）键。

axis：沿行 (0) 或列 (1) 拆分。

level：如果轴是MultiIndex(层次化)，则按一个或多个特定级别进行分组。

as_index：对于聚合输出，返回具有组标签作为索引的对象。仅与DataFrame输入相关。as index=False是有效的sql风格的分组输出。

sort：对组键进行排序。 关闭此功能可获得更好的性能。 请注意，这不会影响每组内的观察顺序。 Groupby 保留每个组内的行顺序。

group_keys：当调用apply时，将组键添加到index以识别片段。

squeeze：如果可能，降低返回类型的维数，否则返回一致的类型。

observed：这仅适用于任何 groupers 是分类的。 如果为真：仅显示分类分组的观察值。 如果为 False：显示分类分组的所有值。

dropna：如果为 True，并且组键包含 NA 值，则 NA 值连同行/列将被删除。 如果为 False，NA 值也将被视为组中的键。
```



### 20. 合并

```python
# 初始化两个DataFrame对象
df1 = pd.DataFrame([['a', 1], ['b', 2]],
                columns=['letter', 'number'])

df2 = pd.DataFrame([['c', 3], ['d', 4]],
                  columns=['letter', 'number'])

display(df1)
display(df2)
```

![image-20221026141406245](笔记图片/image-20221026141406245.png)

![image-20221026141415816](笔记图片/image-20221026141415816.png)

#### （1）纵向连接DataFrame对象

##### 	a. 两个DataFrame对象的列完全相同

```python
# 合并对象
pd.concat([df1, df2])
```

concat默认纵向连接DataFrame对象， 并且合并之后不改变每个DataFrame子对象的index值， 合并之后的DataFrame中index的值0和1重复了两次

![image-20221026141433712](笔记图片/image-20221026141433712.png)

```python
# 如果希望重新设置合并之后的DataFrame对象的index值， 可以添加ignore_index=True参数：
pd.concat([df1, df2], ignore_index=True)
```

![image-20221026145312821](笔记图片/image-20221026145312821.png)

##### b. 两个DataFrame对象的列不完全相同

```python
# 初始化DataFrame对象
df1 = pd.DataFrame([['a', 1], ['b', 2]],
                columns=['letter', 'number'])

df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],
                  columns=['letter', 'number', 'animal'])

display(df1)
display(df3)


# df1中没有animal列， 所以在合并之后的DataFrame对象里， 所对应的元素都被设置成了NaN
```

![image-20221026145408460](笔记图片/image-20221026145408460.png)



```python
# 合并对象
pd.concat([df1, df3], sort=False)  # sort=False : 列的顺序维持原样， 不进行重新排序。
```

![image-20221026150759791](笔记图片/image-20221026150759791.png)

df1中没有animal列， 所以在合并之后的DataFrame对象里， 所对应的元素都被设置成了NaN。

如果只想合并相同的列， 我们可以添加上join='inner'参数：

```python
pd.concat([df1, df3], join='inner')
```

![image-20221026164537553](笔记图片/image-20221026164537553.png)

#### （2）横向合并DataFrame对象

通过设置axis=1, 可以横向合并两个DataFrame对象

```python
# 初始化DataFrame对象
df1 = pd.DataFrame([['a', 1], ['b', 2]],
                columns=['letter', 'number'])

df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],
                  columns=['animal', 'name'])

display(df1)
display(df4)
```

![image-20221026164609918](笔记图片/image-20221026164609918.png)

```python
# 合并对象
pd.concat([df1, df4], axis=1)
```

![image-20221026164640065](笔记图片/image-20221026164640065.png)

### 21. .isin()

#### (1) 直接根据条件进行索引

​	isin()接受一个列表，判断该列中元素是否在列表中。

```python
import numpy as np
import pandas as pd
df=pd.DataFrame(np.random.randn(4,4),columns=['A','B','C','D'])
df
Out[189]: 
          A         B         C         D
0  0.289595  0.202207 -0.850390  0.197016
1  0.403254 -1.287074  0.916361  0.055136
2 -0.359261 -1.266615 -0.733625 -0.790208
3  0.164862 -0.649637  0.716620  1.447703
df['E'] = ['aa', 'bb', 'cc', 'cc']
df
Out[191]: 
          A         B         C         D   E
0  0.289595  0.202207 -0.850390  0.197016  aa
1  0.403254 -1.287074  0.916361  0.055136  bb
2 -0.359261 -1.266615 -0.733625 -0.790208  cc
3  0.164862 -0.649637  0.716620  1.447703  cc
df.E.isin(['aa','cc'])
Out[192]: 
0     True
1    False
2     True
3     True
Name: E, dtype: bool
df[df.E.isin(['aa','cc'])]
Out[193]: 
          A         B         C         D   E
0  0.289595  0.202207 -0.850390  0.197016  aa
2 -0.359261 -1.266615 -0.733625 -0.790208  cc
3  0.164862 -0.649637  0.716620  1.447703  cc

```

#### (2) 根据多条件进行索引

​	此时用&（交集）或者|（并集）进行连接

```python
df[df.E.isin(['aa'])|df.E.isin(['cc'])]
Out[194]: 
          A         B         C         D   E
0  0.289595  0.202207 -0.850390  0.197016  aa
2 -0.359261 -1.266615 -0.733625 -0.790208  cc
3  0.164862 -0.649637  0.716620  1.447703  cc
df[df.E.isin(['aa'])]
Out[195]: 
          A         B        C         D   E
0  0.289595  0.202207 -0.85039  0.197016  aa
```

#### (3) 通过字典的形式传递多个条件

```python
{‘某列’:[条件],‘某列’:[条件],}
```

```python
df['D'] = [1,2,3,4]
df[df.isin({'D':[0,3],'E':['aa','cc']})]
Out[200]: 
    A   B   C    D    E
0 NaN NaN NaN  NaN   aa
1 NaN NaN NaN  NaN  NaN
2 NaN NaN NaN  3.0   cc
3 NaN NaN NaN  NaN   cc

```

#### (4)~相当于is not in

```python
df[~(df.E=='cc')]
Out[202]: 
          A         B         C  D   E
0  0.289595  0.202207 -0.850390  1  aa
1  0.403254 -1.287074  0.916361  2  bb
```

### 22. 列表去空

```python
mytest = [i for i in test if i != '']
```

### 23. value_counts

```
value_counts = df_1['SERVICENAME'].value_counts()
```

![image-20221027162231746](笔记图片/image-20221027162231746.png)

```python
df_rank['排名'].value_counts().rename_axis('排名').reset_index(name='counts')
```

![image-20221027162216343](笔记图片/image-20221027162216343.png)

### 24. apply()

```python
new_df = df[len(df['Title'].split(" "))>=4]
```

```python
# create a new column
df['num_words_title'] = df.apply(lambda x : len(x['Title'].split(" ")),axis=1)
# simple filter on new column
new_df = df[df['num_words_title']>=4]
```

```python
new_df = df[df.apply(lambda x : len(x['Title'].split(" "))>=4,axis=1)]
```

```python
df_merge['Apply_type_count'] = df_merge['Apply_type'].apply(lambda x: len(str(x).split(";")))
```

```python

df3['1'] = df3['1'].apply(lambda x: list(x)[0]+'*'*(len(list(x))-2)+list(x)[-1])
```



### 25.部分匹配

str.[contains](https://so.csdn.net/so/search?q=contains&spm=1001.2101.3001.7020)()：包含一个特定的字符串

```python
df[df['name'].str.contains('li')]
```

### 26. 列长度

```python
# 使用pandas的内置方法.str
test['contentLen2'] = test['content'].str.len()
```

```python
df_merge['Apply_type_count'] = df_merge['Apply_type'].apply(lambda x: len(str(x).split(";")))
```

### 27. 输出格式

#### （1）百分号

```python
# 格式化为float，然后处理成%格式： {:.2f}%
print('{:.3f}%'.format(0.234356*100))  # 23.436%

# 直接使用参数格式化：{:.2%}
print('{:.2%}'.format(0.234356))  # 23.44%

```

`{ }` 的意思是对应`format()`的一个参数，按默认顺序对应，参数序号从0开始，`{0}`对应`format()`的第一个参数，`{1}`对应第二个参数。

```python
rmse_3 = format(random.uniform(9, 8) / 1000, '.3f')
```



### 28. 编码转换

```python
name = "就近办"

print(name) # 就近办
# 字符串转换为字节类型
data = name.encode("utf-8")
print(data) # b'\xe6\xad\xa6\xe6\xb2\x9b\xe9\xbd\x90'

# 把字节转换为字符串
old = data.decode("utf-8")
print(old)
```

### 29. 补充上一行值

```
|  count  | A |  
|---------|---|
|  yes    |2  |
|  yes    |2  |  
|  total  |   |  
|  yes    |2  |  
|  yes    |2  | 
|  total  |   |
```

```python
df.loc[df['count'].eq("total"),"A"] = df['A'].mask(df['A'].eq('')).ffill()
```

```python
print(df)

   count  A
0    yes  2
1    yes  2
2  total  2
3    yes  2
4    yes  2
5  total  2
```

### 30. 取字符串前n位

```python
df["Order_Date"] = df["Shipment ID"].str.extract(r"(\d{8})")
```



### 31. 切片

```python
df1['cityname'] = df1['address_extra'].str.split('/', expand=True)[1]
```

### 32. 小函数

#### （1）sorted()

```python
sorted(L,reverse=True)  # 降序
```

#### （2）zfill()函数

```python
# Python zfill() 方法返回指定长度的字符串，原字符串右对齐，前面填充0。
```

![img](https://img-blog.csdnimg.cn/f75f68ac828d48d1b2d81c9402a3474d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5ZCV5rWp6L2pNjY2,size_20,color_FFFFFF,t_70,g_se,x_16)

```python
# %s,表示格式化一个对象为字符            
# "%±(正负号表示)3(数字表示字符串的长度)s"%(取代s的字符串) 就是%±3s
# %s  string型  表示格式化一个对象为字符    "%s1" %S2   s1放置的是一个字符串(格式化字符串)  S2放置的# 是一个希望要格式化的值
# 就这题而言就是 "%s" %t["year]这样

t={'year':'2013','month':'9','day':'30','hour':'16','minute':'45','second':'2'}
print("%s-%s-%s %s:%s:%s" %(t['year'], t['month'].zfill(2), t['day'].zfill(2), t['hour'].zfill(2), t['minute'].zfill(2), t['second'].zfill(2)))
```

#### （3）startswith()

```python
# 判断 name 变量是否以 "al" 开头,并输出结果（用切片 或 startswith实现）
name = "aleX leNb "
print(name.startswith("al"))
```

#### （4）endswith()

```python
# 判断name变量是否以"Nb"结尾,并输出结果（用切片 或 endswith实现）
name = "aleX leNb "
print(name.startswith("al"))
```

#### （5）replace()

```python
v1 = name.replace("l", "p",n) # n为不超过n次
```

#### （6）split() 

```python
# 将 name 变量对应的值根据 所有的"l" 分割,并输出结果
# 将name变量对应的值根据第一个"l"分割,并输出结果

v2 = name.split("l")
print(v2)  # ['a', 'eX ', 'eNb ']

v3 = name.split("l", 1)
print(v3)  # ['a', 'eX leNb ']
```

#### （7）upper(), lower(), capitalize()，title(), swapcase()

```python
# 将 name 变量对应的值变大写,并输出结果
# 将 name 变量对应的值变小写,并输出结果
print(name.upper())
print(name.lower())
# 将字符串的第一个字母变成大写，即首字母大写，其他字母变小写
new_name = dic1['name'][0].capitalize()
# title() 将字符串中每个单词的首字母大写，其余字母小写，非字母后的第一个字母将转换为大写字母
text.swapcase()#大小写对调
```

#### （8）isdecimal()

```python
# 检查字符串中是否只含有十进制字符
# True - 如果字符串中的所有字符都是十进制字符。
# False - 至少一个字符不是十进制字符。
str.isdecimal()
```

#### （9）join()

```markdown
1、语法：'sep'.join(sep_object)
	参数说明:
	sep：分割符，可为“，、；”等。
	sep_object：分割对象，可为字符串、以及储存字符串的元组、列表、字典。
2、用法：连接任意数量的字符串（包括要连接的元素字符串、元组、列表、字典），用新的目标分隔符连接，返回新的字符串。
```

```markdown
（1）对象为字符串
';'.join('abc') # 输出结果为：'a;b;c'  

string1 = 'good idea'# 定义字符串
' '.join(string1)  输出结果：'g o o d   i d e a' 
# 说明：由于字符串里没指明按字符串之间是怎么连接的，默认每个字符之间插入目标字符
	
（2）对象为元组
tuple1 = ('a','b','c')  #定义元组tuple1
'、'.join(tuple1) # 输出结果为：'a、b、c'

tuple2 = ('hello','peace','world')  #定义元组tuple2
' '.join(tuple2) # 输出结果为：'hello peace world'

（3）对象为列表
b = ['a','b','c'] #定义列表
'、'.join(b) # 输出结果为：'a、b、c'
 
list1 = ['hello','peace','world'] #定义列表
' '.join(list1) # 输出结果为：'hello peace world'

（4）对象为字典
c={'hello':1,'world':2}
';'.join(c) # 输出结果为：'hello;world'

d = {'hello':'hi','world':'2'}
' '.join(d)

（5）储存非字符串的元组、列表、字典等报错，比如元组储存数字进行连接
错误写法：
    a = (1,2,3) #定义元组a
    ';'.join(a)
改正（用for循环）：
	a = (1,2,3) #定义元组a
	';'.join(str(i) for i in a)
# 注意：分割对象储存的对象要为字符串，否则会报错

```

#### （10）set ()

```python
# 列表去重
lis = [1,1,1,1,1,2,2,22]
print(lis)
print(list(set(lis)))
# 输出：[1, 2, 22]


# 元组去重
tup = (1,2,1,2,1,2,223)
print(tup)
print(tuple(set(tup)))
# 输出：(1,2,223)


# 字符串去重，对字符串进行去重和前面两个数据类型去重不同，不能直接用str()函数将去重后的集合转换为字符串
# 而且用这种方法去重后，字符串中的字符顺序也会发生随机变更`
string1 = "aaabbbcccc"
print(string1)
string2 = ''.join(list(set(string1)))
print(string2)
# 输出：
```

#### （11）列表操作（添加、删除）

##### 1）append()

追加，在原列表中尾部追加元素，与extend的区别是每次只追加一个元素。

```python
data_list.append(v1)


# 示例
a = []
a.append([1,2,3,4])
print(a)
a = []
a.extend([1,2,3,4])
print(a)
# 输出：[[1, 2, 3, 4]]
# 输出：[1, 2, 3, 4]
```

##### 2）extend()

批量追加，将一个列表中的元素逐一添加另外一个列表。

```python
tools = ["搬砖","菜刀","榔头"]
tools.extend([11,22,33]) # weapon中的值逐一追加到tools中
print(tools) # ["搬砖","菜刀","榔头",11,22,33]

# 等价于(扩展)
weapon = ["AK47","M6"]
for item in weapon:
    print(item)

# 输出：
#  AK47
#  M6
tools = ["搬砖","菜刀","榔头"]
weapon = ["AK47","M6"]
for item in weapon:
    tools.append(item)  
print(tools) # ["搬砖","菜刀","榔头","AK47","M6"]
```

##### 3）insert()

插入，在原列表的指定索引位置插入值。

```python
user_list = ["苍老师","有坂深雪","大桥未久"]
user_list.insert(0,"马蓉")
user_list.insert(2,"李小璐")
print(user_list) # ['马蓉', '苍老师', '李小璐', '有坂深雪', '大桥未久']

# 案例
name_list = []
while True:
    name = input("请输入购买火车票用户姓名（Q/q退出）：")
    if name.upper() == "Q":
        break
    if name.startswith("刁"):
        name_list.insert(0, name)
    else:
        name_list.append(name)
print(name_list)
```

##### 4）remove()

在原列表中根据值删除（从左到右找到第一个删除）**【慎用，里面没有会报错】**

```python
user_list = ["王宝强","陈羽凡","Alex","贾乃亮","Alex"]
user_list.remove("Alex")
print(user_list)  # ['王宝强', '陈羽凡', '贾乃亮', 'Alex']


user_list = ["王宝强","陈羽凡","Alex","贾乃亮","Alex"]
if "Alex" in user_list:
	user_list.remove("Alex")
print(user_list) # ['王宝强', '陈羽凡', '贾乃亮', 'Alex']


user_list = ["王宝强","陈羽凡","Alex","贾乃亮","Alex"]
while True:
    if "Alex" in user_list:
        user_list.remove("Alex")
	else:
        break
print(user_list) # ['王宝强', '陈羽凡', '贾乃亮']
```

##### 5）choice()

```python
# 案例：自动抽奖程序
import random

data_list = ["iphone12", "二手充气女友", "大保健一次", "泰国5日游", "避孕套"]

while data_list:
    name = input("自动抽奖程序，请输入自己的姓名：")

    # 随机从data_list抽取一个值出来
    value = random.choice(data_list) # "二手充气女友"
    print( "恭喜{}，抽中{}.".format(name, value) )
    
    data_list.remove(value) # "二手充气女友"
```

##### 6）pop()

在原列表中根据索引踢出某个元素（根据索引位置删除，**默认删除末尾的元素**）

```python
user_list = ["王宝强","陈羽凡","Alex","贾乃亮","Alex"]
#               0       1      2      3       4
user_list.pop(1)
print(user_list) #  ["王宝强","Alex","贾乃亮","Alex"]

user_list.pop()
print(user_list) # ["王宝强","Alex","贾乃亮"]

item = user_list.pop(1)
print(item) # "Alex"
print(user_list) # ["王宝强","贾乃亮"]
```

##### 7）clear()

清空源列表

```python
user_list = ["王宝强","陈羽凡","Alex","贾乃亮","Alex"]
user_list.clear()
print(user_list) # []
```

##### 8）index()

根据值获取索引（从左到右找到第一个删除）【慎用，找不到报错】

```python
user_list = ["王宝强","陈羽凡","Alex","贾乃亮","Alex"]
#               0       1      2       3      4
if "Alex" in user_list:
	index = user_list.index("Alex")
	print(index) # 2
else:
    print("不存在") 
```

##### 9）sort()

注意：排序时内部元素无法进行比较时，程序会报错（尽量数据类型统一）。

list.sort()方法只是list也就是列表类型的方法，**只可以在列表类型上调用**。而sorted方法则是**可以接受任何可迭代对象**

```python
# 数字排序
num_list = [11, 22, 4, 5, 11, 99, 88]
print(num_list) #[11, 22, 4, 5, 11, 99, 88]
num_list.sort()  # 让num_list从小到大排序
print(num_list) # [4, 5, 11, 11, 22, 88, 99]
num_list.sort(reverse=True)  # 让num_list从大到小排序
print(num_list) # [99, 88, 22, 11, 11, 5, 4]


# 字符串排序
user_list = ["王宝强", "Ab陈羽凡", "Alex", "贾乃亮", "贾乃", "1"]
#       [29579, 23453, 24378]
#       [65, 98, 38472, 32701, 20961]
#       [65, 108, 101, 120]
#       [49]
print(user_list)
"""
sort的排序原理 [ "x x x" ," x x x x x " ]ord()函数可查看对应字符元素的ASCII码
"""
user_list.sort()
print(user_list)
```

##### 10)reverse()

反转原列表。

```python
user_list = ["王宝强","陈羽凡","Alex","贾乃亮","Alex"]
user_list.reverse()

print(user_list)
```

```python
user_list = ["范德彪","刘华强",'尼古拉斯赵四',"宋小宝","刘能"]
data = user_list[::-1]
```



##### 11）del()

```python
# 删
user_list = ["范德彪", "刘华强", '尼古拉斯赵四']
del user_list[1:]
print(user_list) # 输出 ['范德彪']
```

##### 12）strip()

strip()主要是对字符串进行操作，主要是删除当前你得到的这个字符串的首尾字符，如果在strip()这个括号里面你没有指定字符，也就是如果括号里面为空的话，那么会默认删除当前字符串的首尾的空格和换行符。



strip()去掉字符串两边空格

lstrip()去掉字符串左边空格

rstrip()去掉字符串右边空格



```python
s = 'abcdefg'
s.strip() # 删除前后空格

s1 = 'abcdef\n'
s1.strip() # 删除前后的空格和换行符

s2 = 'abcdef'
s2.strip('a') # 删除前后的字母a
```

##### 13）slice切片

```python
# slice切片函数: 第一个参数-start index 第二个参数-end index,第三个参数为step间距(可省略)

# 例：委派前两个人去完成第一个任务
print(group_list[slice(0,2)])  # ['Tom', 'Allen']
```

```python
# 未指定索引：1) 如果没有指定第一个索引， 那么 python 会默认从表头（这里的表头可以是从左到右的,也可以是从右到左的,看step的正负情况）开始
#           2) 如果没有指定最后一个索引， 那么就会默认从表尾（这里的表尾可以是从左到右的,也可以是从右到左的,看step的正负情况）结束,即为len(list)
# 未指定步长:  1) 默认步长值为 1;
#            2)步长<0, 则从右→左; 如:group_list[:-3:-1] => ['Tony', 'William']
#            3) 步长>0,则从左→右
print(group_list[:2])    # 也可以写成: print(group_list[0:2])
print(group_list[1:4:])  # 也可以写成: print(group_list[1:4])
print(group_list[3::])   # 也可以写成: print(group_list[-2:]) 或 print(group_list[3:])
```



##### 14)get()

```markdown
# my_dict.get(i,0)
get(i,0)是一个字典方法，用于从字典中获取键i对应的值。如果字典中不存在键i，则该方法将返回默认值0。这个方法的优点是，它可以处理字典中不存在的键的情况，从而使代码更加健壮。如果你想从字典中获取一个值，但不确定该键是否存在，那么使用get()函数就是一个好的选择。
```



#### （12) set集合

```python
# 添加集合元素
data.add("周杰伦")
# 删除集合元素
data = {"刘嘉玲", '关之琳', "王祖贤","张曼⽟", "李若彤"}
data.discard("关之琳") 
# 集合交集
s1 = {"刘能", "赵四", "⽪⻓⼭"}
s2 = {"刘科⻓", "冯乡⻓", "⽪⻓⼭"}
s4 = s1.intersection(s2) # 取两个集合的交集 
s3 = s1 & s2   			  # 取两个集合的交集
s4 = s1.union(s2) 		# 取两个集合的并集
s3 = s1 | s2   			# 取两个集合的并集
s4 = s1.difference(s2) 		# 差集，s1中有且s2中没有的值 {"刘能", "赵四"}
s6 = s2.difference(s1)   	# 差集，s2中有且s1中没有的值 {"刘科⻓", "冯乡⻓"}
s3 = s1 - s2   			   # 差集，s1中有且s2中没有的值
s5 = s2 - s1   			   # 差集，s2中有且s1中没有的值

```

#### （13）dict字典

​	py3.6+之后字典就变为有序了。

​	py3.9 新增了一个 `{} | {} `运算。

- 键：必须可哈希。 目前为止学到的可哈希的类型：int/bool/str/tuple；不可哈希的类型：list/set/dict。（集合）
- 值：任意类型。

```markdown
可变类型：dict、list、set
不可变类型：int、long、float、complex、string、bool、tuple
其中可变类型不能作为字典的key，因为它们没有__hash__()方法。
```

```python
# 取元素
info = { 
    "age":12, 
    "status":True, 
    "name":"武沛齐",
    "data":None
}

data1 = info.get("name")
print(data1) # 输出：武沛齐


# 取所有的键、值
info = {"age":12, "status":True, "name":"wupeiqi","email":"xx@live.com"}
data = info.keys()  # py3高仿列表，py2列表
result_key = list(data)
result_values = list(info.values())


# 取所有的键值
info = {"age":12, "status":True, "name":"wupeiqi","email":"xx@live.com"}
data = info.items()
result_items = list(info.items())


# 设置值
data = {
    "name": "武沛齐",
    "email": 'xxx@live.com'
}
data.setdefault("age", 18)


# 更新键值对
info = {"age":12, "status":True}
info.update( {"age":14,"name":"武沛齐"} )   # info中没有的键直接添加；有的键则更新值


# 移除指定键值对
info = {"age":12, "status":True,"name":"武沛齐"}
data = info.pop("age")


# 按照顺序移除（后进先出）
info = {"age":12, "status":True,"name":"武沛齐"}
data = info.popitem() # ("name","武沛齐" )

```

#### （14）str字符串

```python
text="only YOU Loving yoU,你是我的唯一，jUst YoU,我能等你下课吗？能不能一起去逛街？达能小王子"

#大小写转换
text.upper() #大写
text.lower() #小写
text.title()#首字母大写
text.capitalize()#第一个字母大写
text.swapcase()#大小写对调

#字符串的搜索
text.count("o")#搜索并统计"o"出现的次数
text.count("o",28)#搜索并统计，从第28位开始，"o"出现的次数
text.startswith("only")#text以"only"开通
text.startswith("only",2,10)#text的第3-9个字符以"only"开通
text.find("you")#查找you
text.replace("u","V",2)

#填充或者剔除某些信息

"1999".rjust(10,"$")#前一个字符代表填充后字符串的总长度
"1999".rjust(5,"$")
"1999".zfill(9)#用0填充，类似 "1999".rjust(9,"0")
"1999".rjust(9,"0")
"1999".center(50) #在左右两边都假设空格
"   1999   ".strip()#去重左右两边的空格
"1999".strip("9")#去重左右两边的"9"
" 1999 ".strip("9")#去重左右两边的"9",两边是空格没有9

#字符串的分割与合并

text.replace("能",",")
text1=text.replace("能","\n")
print(text1)
print(text.replace("能","\n"))
text.split("能")#以"能"为结点把str拆成一个字列表
text.partition("能") #以"能"为结点把str拆成一个字元组
text.rpartition("能")
text1.splitlines()#识别空行进行分割
text1.split("\n")#同上分割空行
"@".join(text)#把@插入到str的每一个字符中
"12345".join("  ")#重复并拼接
```

#### （15）list列表

```python
len() ：求列表元素个数
max() ：求列表最大值
min() ：求列表最小值
sum() ：求列表的和
sorted() :求排序后的列表序列
list() :将其他数据结构转换成列表
any() :只要列表里有一个True就会返回True
all()：表里的所有元素都是True才会返回True
```

#### （16）翻转

```python
# s[::-1]表示反转s中的元素
# s[:]表示数组中所有子模块
# s[:]=s[::-1]表示将原数组反转后赋值给s中每一个对应的位置
# s=s[::-1]表示将s反转后赋值给新的对象s，与题意原地修改不符

name = "武沛齐"
data = name[::-1]
print(data)
```

#### （17）print()

```python
# sep、end参数
# 输出数据之间换行输出
print("str1","str2",sep="\n")

# 输出数据之间用空格间隔,其实默认格式就是空格间隔
print("str1","str2",sep=" ")<br>print("str1","str2")

# 输出数据之间直接相连,其实无论sep用什么，结果便会替代空格来连接
print("str1","str2",sep="")

```

```python
# end参数默认格式则是换行，end="\n"
print("str1","str2")
print("str1","str2",end="\n")

# 更换连接符号
print("str1","str2",end=",")
```



### 33.os

##### （1）示例

###### 合并子文件：

```python
#coding=utf-8
import os,shutil
from tqdm import tqdm  # 进度条
sourceDir=r"C:\Users\yaoyk\Desktop\work\临时文件\合并测试"
targetDir=r"C:\Users\yaoyk\Desktop\work\临时文件\合并测试1"
for root, dirs, files in os.walk(sourceDir):
    for file in tqdm(files,desc="Waiting..."):
        # 需求1的执行复制操作
        shutil.copy(os.path.join(root,file),targetDir)
        # 需求2的执行重命名操作
        if file.endswith('.txt.txt'):
            os.rename(os.path.join(root,file),os.path.join(root,file[:-4]))
```

![img](https://img2020.cnblogs.com/blog/2630138/202112/2630138-20211220083229002-1041633898.png)



```python
# 提取所有的子目录下的文件，复制到新建的目标目录，并按照读取顺序重新命名
# coding=utf-8
import os,shutil
from tqdm import tqdm
sourceDir=r"C:\Users\yaoyk\Desktop\work\IOCR测试数据\luquan_pic\gdfsheaf"
targetDir=r"C:\Users\yaoyk\Desktop\work\IOCR测试数据\luquan_pic\gdfsheaf1"
count = 0
for root, dirs, files in os.walk(sourceDir):  # 文件源路径、下一级目录名、下一级目录中的文件
    for file in tqdm(files,desc="Waiting..."):
        for file_out in files:
            if file_out:
                count += 1
                # 提取子目录的所有文件复制到目标目录
                shutil.copy(os.path.join(root,file_out),targetDir)
                # 批量重命名
                # if file.endswith('.txt.txt'):
                if file_out and "." in file_out:
                    try:
                        os.rename(os.path.join(targetDir,file_out),os.path.join(targetDir,str(count)+file_out[-4:]))
                    except:
                        os.remove(os.path.join(targetDir,str(count)+file_out[-4:]))
                        os.rename(os.path.join(targetDir, file_out), os.path.join(targetDir, str(count) + file_out[-4:]))
            else:
                continue
```

```python
导入相关类库：import os

获取脚本文件当前路径：path = os.getcwd()

获取脚本文件对应的父路径：p1 = os.path.abspath(os.path.dirname(path) + os.path.sep + ".")

获取脚本文件对应的前两级路径：p1 = os.path.abspath(os.path.dirname(path) + os.path.sep + "..")
```

### 33.添加新列-pandas

```python
# insert()函数，直接插入
# 实例：插入c列
df.insert(loc=2, column='c', value=3)  # 在最后一列后，插入值全为3的c列



# 直接赋值
语法：df[‘新列名’]=新列的值
df['d'] = [1, 2, 3]  # 插入值为[1,2,3]的d列
# 注：该方法不可以选择插入新列的位置，默认为最后一列。如果新增的一列值相同，直接为其赋值一个常量即可；如果插入值不同，为列表格式，需与已有列的行数长度一致，如举例中原来列为3行，新增列也必须有3个值。



# reindex()函数
语法：df.reindex(columns=[原来所有的列名,新增列名],fill_value=值)
df1 = df.reindex(columns=['a', 'b', 'c', 'd', 'e'])  # 不加fill_value参数，默认值为Nan
df2 = df.reindex(columns=['a', 'b', 'c', 'd', 'e'], fill_value=1)  # 加入fill_value参数，填充值为1
# 注：该方法需要把原有的列名和新列名都加上，如果列名过多，就比较麻烦。


# concat()函数
原理：利用拼接的方式，添加新的一列。好处是可以同时新增多个列名。
df1 = pd.concat([df1, pd.DataFrame(columns=['f'])])



# loc()函数
原理：利用loc的行列索引标签来实现。
语法：df.loc[:,新列名]=值
df1.loc[:, 'g'] = 0

```

pandas中一个Dataframe，经常需要根据其中一列再新建一列，比如一个常见的例子：需要根据分数来确定等级范围，下面我们就来看一下怎么实现。

```python
def getlevel(score):
    if score < 60:
        return "bad"
    elif score < 80:
        return "mid"
    else:
        return "good"

def test():
    data = {'name': ['lili', 'lucy', 'tracy', 'tony', 'mike'],
            'score': [85, 61, 75, 49, 90]
            }
    df = pd.DataFrame(data=data)
    # 两种方式都可以
    # df['level'] = df.apply(lambda x: getlevel(x['score']), axis=1)
    df['level'] = df.apply(lambda x: getlevel(x.score), axis=1)
	
    print(df)
```

要实现上面的功能，主要是使用到dataframe中的apply方法。

上面的代码，对dataframe新增加一列名为level，level由分数一列而来，如果小于60分为bad，60-80之间为mid，80以上为good。

其中axis=1表示原有dataframe的行不变，列的维数发生改变。





### 34. try...except()

### 35. logger()



## 四、**MySQL**

### **1.判断周几**

```mysql
select if(dayofweek(curdate()) = 1,7,dayofweek(curdate()) -1);
```

### 2. 查询近x天/周/月/季/年

```mysql
# 今天
select * from 表名 where to_days(时间字段名) = to_days(now());

# 昨天
SELECT * FROM 表名 WHERE TO_DAYS( NOW( ) ) - TO_DAYS(时间字段名) <= 1;

#7天
SELECT * FROM 表名 where DATE_SUB(CURDATE(), INTERVAL 7 DAY) <= date(时间字段名);

#近30天
SELECT * FROM 表名 where DATE_SUB(CURDATE(), INTERVAL 30 DAY) <= date(时间字段名);

#本月
SELECT * FROM 表名 WHERE DATE_FORMAT( 时间字段名, '%Y%m' ) = DATE_FORMAT( CURDATE( ) , '%Y%m' );

#上一月
SELECT * FROM 表名 WHERE PERIOD_DIFF( date_format( now( ) , '%Y%m' ) , date_format( 时间字段名, '%Y%m' ) ) =1;

#查询本季度数据
select * from `ht_invoice_information` where QUARTER(create_date)=QUARTER(now());

#查询上季度数据
select * from `ht_invoice_information` where QUARTER(create_date)=QUARTER(DATE_SUB(now(),interval 1 QUARTER));

#查询本年数据
select * from `ht_invoice_information` where YEAR(create_date)=YEAR(NOW());

#查询上年数据
select * from `ht_invoice_information` where year(create_date)=year(date_sub(now(),interval 1 year));

#查询当前这周的数据

SELECT name,submittime FROM enterprise WHERE YEARWEEK(date_format(submittime,'%Y-%m-%d')) = YEARWEEK(now());

#查询上周的数据
SELECT name,submittime FROM enterprise WHERE YEARWEEK(date_format(submittime,'%Y-%m-%d')) = YEARWEEK(now())-1;

#查询当前月份的数据
select name,submittime from enterprise   where date_format(submittime,'%Y-%m')=date_format(now(),'%Y-%m');

#查询距离当前现在6个月的数据

select name,submittime from enterprise where submittime between date_sub(now(),interval 6 month) and now();

#查询上个月的数据
select name,submittime from enterprise   where date_format(submittime,'%Y-%m')=date_format(DATE_SUB(curdate(), INTERVAL 1 MONTH),'%Y-%m');

select * from ` user ` where DATE_FORMAT(pudate, ' %Y%m ' ) = DATE_FORMAT(CURDATE(), ' %Y%m ' ) ;

select * from user where WEEKOFYEAR(FROM_UNIXTIME(pudate,'%y-%m-%d')) = WEEKOFYEAR(now());

select * 
from user 
where MONTH (FROM_UNIXTIME(pudate, ' %y-%m-%d ' )) = MONTH (now());

select * 
from [ user ] 
where YEAR (FROM_UNIXTIME(pudate, ' %y-%m-%d ' )) = YEAR (now())
and MONTH (FROM_UNIXTIME(pudate, ' %y-%m-%d ' )) = MONTH (now());

select * 
from [ user ] 
where pudate between 上月最后一天
and 下月第一天
where   date(regdate)   =   curdate();


select   *   from   test   where   year(regdate)=year(now())   and   month(regdate)=month(now())   and   day(regdate)=day(now());

SELECT date( c_instime ) ,curdate( )
FROM `t_score`
WHERE 1
LIMIT 0 , 30;
```

### 3、建表

```sql
-- y_test.qlt_qlsx definition

CREATE TABLE `qlt_qlsx` (
  `ROWGUID` varchar(50) NOT NULL COMMENT '权力唯一标识',
  `UPDATE_DATE` datetime NOT NULL COMMENT '写入同步时间',
  `UPDATE_TYPE` varchar(1) NOT NULL COMMENT '权力更新类型',
  `QL_KIND` varchar(2) NOT NULL COMMENT '权力事项类型',
  `QL_ATT` varchar(2) DEFAULT NULL COMMENT '权力属性',
  `UNUnifyDo_Other` varchar(1) DEFAULT NULL COMMENT '不接入统一办件库其他原因',
  `IsHasOwnFlow` varchar(2) DEFAULT NULL COMMENT '是否个性化流程（仅用于乡镇延伸事项）',
  `bszn_url` varchar(150) DEFAULT NULL COMMENT '办事指南URL',
  `NoSuit_ReasonDesc` text COMMENT '不适宜网上申报原因描述',
  `business_regulate` text COMMENT '业务审查规范',
  PRIMARY KEY (`tongID`,`ROWGUID`,`UPDATE_DATE`) USING BTREE,
  KEY `tongID_index` (`tongID`) USING BTREE,
  KEY `ROWGUID_index` (`ROWGUID`) USING BTREE,
  KEY `UPDATE_DATE_index` (`UPDATE_DATE`) USING BTREE,
  KEY `qlt_qlsx_index` (`tongID`,`ROWGUID`,`UPDATE_DATE`) USING BTREE,
  KEY `QL_INNER_CODE_index` (`QL_INNER_CODE`) USING BTREE,
  KEY `ql_kind_index` (`QL_KIND`,`QL_MAINITEM_ID`,`QL_SUBITEM_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=COMPRESSED KEY_BLOCK_SIZE=8 COMMENT='权力信息发布表';
```



## 五、**Linux**

### 1. 查看行号

```shell
set nu

set number
```

### 2. 搜索关键字

vim工具

```markdown
1、进入vi中，编辑模式中先按下键盘上"esc"跳转成命令输入模式

2、输入斜杠"/"，这时屏幕会跳转到底部，输入栏出现"/"

3、输入你需要查找的关键字，回车键

4、如果要继续查找下一个关键字，输入n

5、查找上一个关键字，输入N（大写）

```

### 3. top

```ssh
%us：表示用户空间程序的cpu使用率（没有通过nice调度）

%sy：表示系统空间的cpu使用率，主要是内核程序。

%ni：表示用户空间且通过nice调度过的程序的cpu使用率。

%id：空闲cpu

%wa：cpu运行时在等待io的时间

%hi：cpu处理硬中断的数量

%si：cpu处理软中断的数量

%st：被虚拟机偷走的cpu
```

```shell
ps -ef | grep 2761
```



### 4. 内核

```shell
cat /etc/issue （简单）

cat /etc/lsb-release（具体）

uname -a（内核）

sudo uapdate-grub
**硬盘信息
cat /sys/block/sda/device/model
```



## 六、windows

### 1. 查看文件前几行

在Window10的[PowerShell](https://so.csdn.net/so/search?q=PowerShell&spm=1001.2101.3001.7020)里，使用 type XXX|Select -First n 表示查找XXX文件的前n条记录，而 type XXX|Select -Last n 表示查找XXX文件的最后n条记录。

#### （1）统计的文件的总行数

```markdown
cmd
find /V "" /C FileList.txt
```

![img](https://img-blog.csdnimg.cn/20210710111740242.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NhbnFpbWE=,size_16,color_FFFFFF,t_70)

#### (2)查看文件的前10行

```markdown
powershell
type FileList.txt|Select -First 10
```

![img](https://img-blog.csdnimg.cn/20210710111255924.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NhbnFpbWE=,size_16,color_FFFFFF,t_70)

#### (3)查看文件的最后10行

```markdown
powershell
type FileList.txt|Select -Last 10
```

![img](https://img-blog.csdnimg.cn/20210710111301572.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NhbnFpbWE=,size_16,color_FFFFFF,t_70)

## 七、ERROR

1. AssertionError: 3 columns passed, passed data had 4 columns

```markdown
使用pandas.DataFrame构造函数时每个子列表被解释为一行的事实
```

2. AttributeError: ‘NoneType‘ object has no attribute ‘reset_index‘

```python
# 原始
df.sort_values(['datatime'],inplace=True).reset_index(drop=True）
```

```python
# 修改后
df.sort_values(['datatime'],inplace=True)
df.reset_index(drop=True，inplace=True）
```

3. not all arguments converted during string formatting,not all arguments converted during string formatting

检查mysql “%s”数量是否对应；检查功能函数返回值的字段数是否对应

4. pandas筛选报错ValueError: Cannot mask with non-boolean array containing NA / NaN values

```python
df = df.loc[df["列名"].str.contains("需要筛选的字符串"),:]
```

```python
#解决方案是：在筛选中加上"na=False"，这意思是：遇到非字符串的情况，直接忽略
df = df.loc[df["列名"].str.contains("需要筛选的字符串", na=False),:]
```

5.ValueError: The truth value of a [Series](https://so.csdn.net/so/search?q=Series&spm=1001.2101.3001.7020) is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().

```
出现此错误是因为Python的逻辑运算符(and、or、not)是用来与布尔值（boolean）一起使用的，所以当试图将它们与序列或数组一起使用时，系统程序不清楚如何确定它是真的还是假的，因此会导致ValueError。
```



## 八、XML转JSON

```python
#	将python对象编码成Json字符串
#   json库dumps()是将dict转化成json格式,loads()是将json转化成dict格式。
#   dumps()方法的ident=1,格式化json
parser_data = xmltodict.parse(xml_file)
json_conversion = json.dumps(parser_data, indent=4, ensure_ascii=False)
json_conversion = json_conversion.replace("null", "''")
```

## 九、数学

#### 1. 数学符号

```markdown
Α α：阿尔法 Alpha。

Β β：贝塔 Beta。

Γ γ：伽玛 Gamma。

Δ δ：德尔塔 Delte 。

Ε ε：艾普西龙 Epsilon。

Ζ ζ  ：捷塔 Zeta。

Ε η：依塔 Eta。

Θ θ：西塔 Theta。

Ι ι：艾欧塔 Iota。

Κ κ：喀帕 Kappa。

∧ λ：拉姆达 Lambda。

Μ μ：缪 Mu。

Ν ν：拗 Nu。

Ξ ξ：克西 Xi。

Ο ο：欧麦克轮 Omicron。

∏ π：派 Pi。

Ρ ρ：柔 Rho。

∑ σ：西格玛 Sigma。

Τ τ：套 Tau。

Υ υ：宇普西龙 Upsilon。

Φ φ：fai Phi。

Χ χ：器 Chi。

Ψ ψ：普赛 Psi。

Ω ω：欧米伽 Omega。
```

#### 2. 数学公式编辑

![image-20230209085310295](笔记图片/image-20230209085310295.png)

![image-20230209085336659](笔记图片/image-20230209085336659.png)

![image-20230209085357010](笔记图片/image-20230209085357010.png)

![image-20230209085413553](笔记图片/image-20230209085413553.png)

![image-20230209085428321](笔记图片/image-20230209085428321.png)

![image-20230209085442697](笔记图片/image-20230209085442697.png)

## 十、深度学习

#### 1. conda

```python
python -m pip install --upgrade pip
python -m pip install --upgrade setuptools

pip install -i https://pypi.tuna.tsinghua.edu.cn/simple opencv-python
```

```python
conda list 查看安装了哪些包
conda info --envs
conda env list 或 conda info -e 查看当前存在哪些虚拟环境
conda update conda 检查更新当前conda
conda create -n your_env_name python=X.X（2.7、3.6等)命令创建python版本为X.X、名字
conda remove -n your_env_name(虚拟环境名称) --all删除环境
conda remove --name your_env_name  package_name删除某个包

conda install python=版本号 # 更改当前环境的python版本

```

```shell
sudo rm /var/lib/dpkg/lock 解锁
sudo rm /var/lib/apt/lists/lock
```

```python
conda 添加镜像
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/

conda config --set show_channel_urls yes

查看全部的镜像：
conda config --show channels

移除想移除的镜像：
conda config --remove channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/
```

#### 2. doccnao

https://blog.csdn.net/WASEFADG/article/details/124536722

```python
pip install doccano -i https://pypi.tuna.tsinghua.edu.cn/simple/
```

```python
# 初始化数据库
doccano init
 
# 创建一个super user。这里要把pass改成你需要的密码。当然，用户名也可以改成别的。
doccano createuser --username admin --password password
```

```python
# 启动webserver
doccano webserver --port 8000
```

```python
# 启动任务队列
doccano task
```

```
打开浏览器（最好是Chrome），在地址栏中输入http://127.0.0.1:8000/并回车。
```

```python
# 多人标注：设置用户名= admin,密码=pass
 
doccano createuser --username user1 --password 123456
```

#### 3. 模型训练

![image-20221206103612747](笔记图片/image-20221206103612747.png)



![image-20221206154516691](笔记图片/image-20221206154516691.png)



train loss 下降，val loss下降，说明网络仍在学习； 奈斯，继续训练
train loss 下降，val loss上升，说明网络开始过拟合了；赶紧停止，然后数据增强、正则
train loss 不变，val loss不变，说明学习遇到瓶颈；调小学习率或批量数目
train loss 不变，val loss下降，说明数据集100%有问题；检查数据集标注有没有问题
train loss 上升，val loss上升，说明网络结构设计不当，训练超参数设置不当，数据集经过清洗等问题。
https://blog.csdn.net/weixin_46969441/article/details/121075809



#### **ERROR**

1.  问题：“You will need to adjust your conda configuration to proceed”

```
解决:删除已经设定好滴默认镜像源,执行后就恢复了原来的源
conda config --remove-key channels
```

$$

$$









## 十一、PyCharm

代码编辑快捷键

|      |      |      |
| ---- | ---- | ---- |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |

2、搜索/替换快捷键
序号	快捷键	作用
1	CTRL+F	查找
2	F3	查找下一个
3	SHIFT+F3	查找上一个
4	CTRL+R	替换
5	CTRL+SHIFT+F	指定路径下查找
6	CTRL+SHIFT+R	指定路径下替换
3、代码运行快捷键
序号	快捷键	作用
1	ALT+SHIFT+F10	选择程序文件并运行代码
2	ALT+SHIFT+F9	选择程序文件并调试代码
3	SHIFT+F10	运行代码
4	SHIFT+F9	调试代码
5	CTRL+SHIFT+F10	运行当前编辑区的程序文件
4、代码调试快捷键
序号	快捷键	作用
1	F8	单步
2	F7	单步（无函数时同F8）
3	SHIFT+F8	单步跳出
4	ALT+F9	运行到光标所在位置处
5	ALT+F8	测试语句
6	F9	重新运行程序
7	CTRL+F8	切换断点
8	CTRL+F8	查看断点
5、应用搜索快捷键
序号	快捷键	作用
1	ALT+F7	查找应用
2	CTRL+F7	在文件中查找应用
3	CTRL+SHIFT+F7	在文件中高亮应用
4	CTRL+ALT+F7	显示应用
6、代码重构快捷键
序号	快捷键	作用
1	F5	复制文件
2	F6	移动文件
3	SHIFT+F6	重命名
4	ALT+DELETE	安全删除
5	CTRL+F6	改变函数形式参数
6	CTRL+ALT+M	将代码提取为函数
7	CTRL+ALT+V	将代码提取为变量
8	CTRL+ALT+C	将代码提取为常数
9	CTRL+ALT+F	将代码提取为字段
10	CTRL+ALT+P	将代码提取为参数
7、动态模块快捷键
序号	快捷键	作用
1	CTRL+ALT+J	使用动态模板包裹
2	CTRL+J	插入动态模板
8、导航快捷键
序号	快捷键	作用
1	CTRL+N	进入类
2	CTRL+SHIFT+N	进入文件
3	CTRL+ALT+SHIFT+N	进入符号
4	CTRL+←←	进入上一个编辑位置
5	CTRL+→→	进入下一个编辑位置
6	CTRL+→→	进入下一个编辑位置
7	SHIFT+ESC	隐藏活动/最后活动的窗口
8	CTRL+SHIFT+F4	关闭活动的运行/消息/查找等窗口
9	CTRL+G	显示光标所在行与列
10	CTRL+E	弹出最近打开的文件
11	CTRL+ALT+←/→←/→	向前/向后导航
12	CTRL+SHIFT+BACKSPACE	导航到最后编辑的位置
13	CTRL+B	跳转到声明部分
14	CTRL+CLICK(鼠标左键)	跳转到声明部分
15	CTRL+ALT+B	跳转到代码实施部分
16	CTRL+SHIFT+I	打开快速定义查找
16	CTRL+SHIFT+B	跳转到类型说明
17	CTRL+U	跳转超类/方法
18	CTRL+↑↑	跳转到上一个方法
19	CTRL+↓↓	跳转到下一个方法
20	CTRL+[	跳转到代码块的开头
21	CTRL+]	跳转到代码块的结尾
22	CTRL+F12	弹出文件结构
23	CTRL+H	弹出类层次结构
24	CTRL+SHIFT+H	弹出方法层次结构
25	CTRL+ALT+H	弹出调用层次结构
26	F2/SHIFT+F2	下一个/上一个错误
27	F4	查看源代码
28	ALT+HOME	显示导航栏
29	F2/SHIFT+F2	下一个/上一个错误
30	F11	增加书签
31	CTRL+F11	增加数字/字母书签
32	CTRL+SHIFT+[1-9]	增加数字书签
33	SHIFT+F11	显示书签
9、通用快捷键
序号	快捷键	作用
1	ALT+[0-9]	打开相应的工具窗口
2	CTRL+ALT+Y	同步
3	CTRL+SHIFT+F12	最大化编辑器
4	ALT+SHIFT+F	添加到收藏夹
5	ALT+SHIFT+I	使用当前配置文件检查当前文件
6	CTRL+ALT+S	快速出现设置对话框
7	CTRL+SHIFT+A	查找并调试编辑器的功能
8	ALT+TAB	在选项卡和工具窗口之间切换

## 十二、正则表达式

Road To Coding:

https://www.r2coding.com/#/README?id=%e5%9f%ba%e7%a1%80%e6%ad%a3%e5%88%99%e8%a1%a8%e8%be%be%e5%bc%8f%e9%80%9f%e6%9f%a5%e8%a1%a8

![img](https://oa.epoint.com.cn/EpointCommunity/eWebEditor/uploadfile/20190628214425871001.png)

































## 羊言羊语

```
复方氨酚那敏颗粒：主要成分是对乙酰氨基酚、咖啡因、马来酸氯苯那敏和人工牛黄。
功效：适用于缓解普通感冒及流行性感冒引起的发热、头痛、四肢酸痛、打喷嚏、流鼻涕、鼻塞、咽痛等症状，没吃过，功效不确定。
可能不良反应：轻度头晕、乏力、恶心、上腹不适、口干、食欲缺乏和皮疹等，如出现反应可减量、停药。

感康：主要成分是对乙酰氨基酚、盐酸金刚烷胺、人工牛黄、马来酸氯苯那敏等。
功效：
1、酰氨基酚：具有解热镇痛作用，可治疗感冒、发热、肌肉酸痛等。 
2、盐酸金刚烷胺：具有抗病毒作用。 
3、人工牛黄：具有解热、抗惊厥作用。 
4、马来酸氯苯那敏：具有抗过敏作用，可缓解感冒时流鼻涕、打喷嚏、流泪等过敏反应。
可能不良反应：轻度头晕、乏力、恶心、上腹部不适、口干、食欲缺乏和皮疹等，这个亲测药劲有点大主要是头晕，睡一会儿就行。

感冒清热颗粒：主要成分是薄荷，防风，柴胡，紫苏，葛根，苦杏仁，白芷，苦地丁，芦根等。
功效：感冒清热颗粒具有疏散，风寒表清热，用于风寒感冒，头痛发热，鼻流清涕，咳嗽咽干等病症的治疗。
可能不良反应：口干舌燥、手足心热等阴伤症状或其他身体不适，亲测问题不大，用开水慢慢送服。

蓝芩口服液：主要成分是板蓝根、黄芩、栀子、黄柏、胖大海。
功效：急性咽炎、肺胃实热症所致的咽痛、咽干、咽部灼热。
可能不良反应:个别患者服用蓝芩口服液后出现轻度腹泻,问过其他人基本没出现不好的反应，喝它。

999感冒灵：主要成分是主成分包括有三叉苦、岗梅、金盏银盘、薄荷油、野菊花等中成药，还包含一些西药有马来酸氯苯那敏、咖啡因、对乙酰氨基酚等,辅料是蔗糖粉。
功效：解热镇痛，可以用于感冒引起的头痛、鼻塞、流涕、咽痛等症状。
可能不良反应：主要是导致患者出现胃肠道的不适，一天3次每次一袋热水冲服正常喝就行，还甜蛮好喝的。

莲花清瘟胶囊：主要成分是连翘、金银花、炙麻黄、炒苦杏仁、石膏、板蓝根、绵马贯众、鱼腥草、广藿香、大黄、红景天、薄荷脑、甘草。
功效：用于治疗流行性感冒热毒袭肺证，症见发热或高热、恶寒、肌肉酸痛、鼻塞流涕、咳嗽、头痛、咽干咽痛、舌偏红、苔黄或黄腻等。吃的比较少，功效不确定。
可能不良反应：胃肠道不良反应如恶心、呕吐、腹痛、腹泻、腹胀、反胃，以及皮疹、瘙痒、口干、头晕。

综上，前两天注重退烧，其实多喝999感冒灵基本够了，该有的成分都有；后面喉咙痛可以吃点 雪梨炖冰糖，亲测做起来方便也好吃；咳嗽提前准备点川贝枇杷膏，枇杷膏在喉咙含一会儿，吃枇杷膏不能喝水！不能喝水！不能喝水！


```





**python新手常见的报错提示**
在运行或编写一个程序时常会遇到错误异常，这时python会给你一个错误提示类名，告诉出现了什么样的问题（Python是面向对象语言，所以程序抛出的异常也是类）。能很好的理解这些错误提示类名所代表的意思，可以帮助你在最快的时间内找到问题所在，从而解决程序上的问题是非常有帮助的。

搜集了一些python最重要的内建异常类名，并做了简单的介绍：

AttributeError：属性错误，特性引用和赋值失败时会引发属性错误

NameError：试图访问的变量名不存在

SyntaxError：语法错误，代码形式错误

Exception：所有异常的基类，因为所有python异常类都是基类Exception的其中一员，异常都是从基类Exception继承的，并且都在exceptions模块中定义。

IOError：一般常见于打开不存在文件时会引发IOError错误，也可以解理为输出输入错误

KeyError：使用了映射中不存在的关键字（键）时引发的关键字错误

IndexError：索引错误，使用的索引不存在，常索引超出序列范围，什么是索引

TypeError：类型错误，内建操作或是函数应于在了错误类型的对象时会引发类型错误

ZeroDivisonError：除数为0，在用除法操作时，第二个参数为0时引发了该错误

ValueError：值错误，传给对象的参数类型不正确，像是给int()函数传入了字符串数据类型的参数。



## **Q&A**



### **金华项目**

#### 20221129-就近办、窗口

```markdown
1. 区分办件所在地： 区县、乡镇、村社--确认办理地点
2. 政银合租网点办件量--数据
3. 办件量->事项数、办件量占比->事项数占比

接件量：办件受理表（dsc_jh_ads_share_pre_accept_s_h）
```

#### 20221212-就近办（方案更新、脑图、代码）

```markdown
 1. line63、事项下沉度
 2. 行政区划表关联
```

#### 20230320-模型成效

```
审批效率模型按月为周期分析政务服务办件库涉及事项的办理效率，运用孤立森林算法监测全市不同地区不同部门同个事项的办理时间、环节数据的异常值，构建办理时长和环节的离散指数，根据两指数之和的正、负偏向来评估区县、部门的办事效率星级，结果正偏离5星，负偏离3星，其余的效率正常的为4星。
```

审批效率优化模型是一种用孤立森林算法来分析本区域、部门和事项的办件效率在所有区域、同类部门和同个事项的效率离散值，来得出本区域、部门和事项的效率星级。星级评价三星为效率较低、四星为效率正常、五星为效率较高，对效率较低的区域、部门、事项提供可优化的建议。

政务服务办件库涉及事项的办理效率的方法。按照一个月的时间周期来分析，通过运用孤立森林算法来监测全市不同地区、不同部门、同一种事项的办理时间和环节数是否异常。在这个过程中，模型会把办理时长和环节数的离散指数分别计算出来，并将这两个指数相加，以此来评估区县、部门的办事效率星级。如果结果正偏离5星，说明该区县或部门的效率非常高；如果负偏离3星，说明该区县或部门的效率较低；其余如果效率正常，则为4星。

```
事项优化模型按月为周期识别政务服务事项办理差异的优化空间，运用孤立森林算法监测全市不同区域不同部门同个事项的承诺办理时间、必填材料数、环节数、最少跑动次数、办理广度五类数据异常值，构建五类离散指数，根据指数之和的正、负偏向来评估区县、部门的办理事项星级，结果正偏离5星，负偏离3星，其余的效率正常的为4星。
```

事项优化模型是一种用来识别政务服务事项办理差异的方法。按照一个月的时间周期来进行分析，通过运用孤立森林算法来监测全市不同区域、不同部门、同一种事项的承诺办理时间、必填材料数、环节数、最少跑动次数、办理广度这5个维度的数据是否异常。在这个过程中，模型会把这5个维度的离散指数分别计算出来，并将这些指数相加，以此来评估区县或部门的事项办理星级。如果结果正偏离5星，说明该区县或部门的事项办理效率非常高；如果负偏离3星，说明该区县或部门的事项办理效率较低；如果效率正常，则为4星。

```
大厅窗口调配模型按月为周期分析政务服务大厅窗口的服务效能，运用孤立森林算法监测全市各个大厅每个窗口取叫号时间数据、办理事项数据的异常值，构建全市各个大厅窗口办理事项等待时间离散指数，根据窗口等待时间离散指数之和的正、负偏向来评估窗口办事效率星级，结果正偏离5星，负偏离3星，其余的效率正常的为4星。
```

大厅窗口调配模型是一种用来分析政务服务大厅窗口服务效能的方法。按照一个月的时间周期来进行分析，通过运用孤立森林算法来监测全市各个大厅每个窗口取叫号时间、办理事项数据是否异常。在这个过程中，模型会将全市各个大厅窗口办理事项等待时间的离散指数计算出来，以此来评估窗口办事效率星级。如果结果正偏离5星，说明该窗口的办事效率非常高；如果负偏离3星，说明该窗口的办事效率较低；如果效率正常，则为4星。

```
就近办模型按月为周期分析审批服务能否更好更多的延伸到乡镇（街道）、城乡社区，实现事项就近能办、多点可办、少跑快办，运用孤立森林算法监测全市各个区县、乡镇、村社的事项数、接件量、政银合作办件量、帮办代办数量数据的异常值，构建就近办评价离散指数，根据离散指数之和的正、负偏向来评估就近办效率星级，结果正偏离5星，负偏离3星，其余的效率正常的为4星。
```

就近办模型是一种按照一个月的时间周期来分析审批服务能否更好更多的延伸到乡镇（街道）、城乡社区，希望实现事项就近能办、多点可办、少跑快办的目标。在此过程中，我们运用孤立森林算法来监测全市各个区县、乡镇、村社的事项数、接件量、政银合作办件量、帮办代办数量这4个维度的数据是否异常。在这个过程中，模型会把这个4个维度的离散指数分别计算出来，并将这些指数相加，以此来评估就近办效率星级。如果结果正偏离5星，说明就近办效率非常高；如果负偏离3星，说明就近办效率较低；如果效率正常，则为4星。

```
原始描述
算法介绍：
孤立森林算法不借助类似距离、密度等指标去描述样本与其他样本的差异，而是直接去刻画所谓的疏离程度(isolation)，因此该算法简单、高效，在工业界应用较多。在孤立森林中，递归地随机分割数据集，直到所有的样本点都是孤立的。在这种随机分割的策略下，异常点通常具有较短的路径。
```



算法介绍：
孤立森林算法，用数据点间的距离计算各点之间的密集程度，来判断某个点是否为异常点。如上图的示例，统计不同区县、同一部门、同一个事项的平均办理时间，利用各点分布的密集程度来查找异常点。在30min~50min之间，可以认为这7个区县的办事时间分布较为集中，属于正常范围内；市本级、磐安县的办理时间较短，则效率较高；武义县的办理时间较长，则效率较低。

算法介绍：
孤立森林算法，用数据点间的距离计算各点之间的密集程度，来判断某个点是否为异常点。如上图的示例，统计出不同区县、同一部门、同一个事项的平均办理环节数。在2个~4个环节数之间，可以认为这6个区县的办事环节数分布的较为集中，属于正常范围内；市本级、磐安县的办理环节数较少，则效率较高；义乌市、武义县的办理环节数较多，则效率较低。

算法介绍：
孤立森林算法，根据各数据点之间的距离计算出每个点的离散指数，离散指数的大小可以表示数据点是否偏离（离散指数为0，则点在正常范围内；离散指数为正或者为负，则该点偏离了正常的范围）。将该事项下办理时长、环节数的离散指数相加，计算的结果如果正数评为5星；如果负数评为3星；如果是0评为4星。



#### 20230321

标准化页面，简洁，不需要框框条条，无感交换

模型：不同地区、同一个事项，







### 政策要素识别

#### 20221209-苏商通要素识别

```markdown
Q: 富文本转纯文本

1. 项目实际数据格式，数据如何获取，如何存储的,当前的富文本包含什么内容
2. 项目上可以怎么转，能转到什么程度
	字符串替换、正则表达式
3. 是否要中研院重新训练（只影响需要分类的字段）


标版，代码项映射
```

人工录入的过程，

数据保存？政策原文件，

平台改造情况

### 智能场景描述

 1.外卖员违规行为识别

2.商贩占道经营识别



### ChatGpt

```
接下来我会给你指令，生成相应的图片，我希望你用Markdown语言生成，不要用反引号，不要用代码框，你需要用Unsplash API，遵循以下的格式：https://source.unsplash.com/1600x900/?< PUT YOUR QUERY HERE >。你明白了吗？
```





ChatGPT（Chat-oriented Generative Pretrained Transformer）是一种聊天式预训练语言模型，用于自动生成聊天对话。它基于开放预训练语言模型GPT（Generative Pretrained Transformer），并通过特定的数据集和更新的训练算法来训练，以改善聊天的自然语言理解（NLU）和自然语言生成（NLG）能力。ChatGPT具有更强的聊天能力，可以自动生成更自然、更复杂的对话，并可以根据上下文保持对话的流畅性和连贯性。



PPO模型是一种基于梯度的强化学习方法，可以在智能客服中使用。它的原理流程如下：

1. 首先，选择一个客户会话，将其表示为一个状态，例如客户的偏好、访问的频率等信息。

2. 使用深度神经网络模型来预测客户可能采取的动作，并根据客户的回应来调整参数，以获得最佳的客户回应。

3. 通过观察客户的反应来计算奖励，并使用梯度下降方法来更新模型参数，以便针对特定客户更准确地预测行为。

4. 重复上述步骤，直至模型能够以最佳方式服务每个客户为止。





ChatGPT的原理流程如下：

1. 输入：聊天系统接收到来自用户的输入文本（上下文）

2. 编码：将用户输入文本进行编码，转换为计算机可以理解的数据格式

3. 预处理：预处理输入文本，包括去除噪声、拼写检查、语法检查等

4. 模型训练：使用已有的语料库训练模型，使模型能够理解上下文

5. 语义理解：使用模型对用户输入的文本进行语义理解，提取出意图

6. 回复生成：使用模型根据已提取出的意图，生成回复文本

7. 输出：将生成的回复文本发送给用户





















![img](https://cdn.openai.com/chatgpt/draft-20221129c/ChatGPT_Diagram.svg)

1. 预训练基础大模型，得到 SFT 模型
2. 标注排序数据集 ，训练奖励模型 RM。
3. 使用强化学习方法 PPO，RM 的输出作为奖惩，进一步微调 SFT ，使它能够得分越来越高，得到 InstructGPT/ChatGPT 模型











我想更新一下我的食品经营许可证

请选择您要变更的内容：

1. 法定代表；

2. 主体业态；

3. 经营地址；

4. 外设仓库地址



主体业态

请选择您变更后的经营范围:

1. 仅变更主体业态 
2. 增加自动售货设施设备 
3. 增加散装熟食
4. 适用食品经营许可申请人承诺制的连锁企业

增加散装熟食

(一) 通用材料:
1、由申请者签署的《食品经营许可证》变更申请书1份;
2、变更后的其他主体资格证明文件复印件(事业单位、社会组织、党政机关等需提交) ;
3、《食品经营许可证》正、副本原件:
4、食品经营许可承诺书。
(二) 依变更内容提供:
1、变更主体业态，经营项目的，应按照变更后的主体业态，经营项目提交相应资料：
a、设施设备平面布局图 (食品:包含必要的货物摆放设施设备和办公设备等:餐饮:包含必要的冷藏冷冻设备、消毒设备、清洗设备、制作设备、用餐区布局等)；
b、增加申请销售散装熟食制品的，应当提交与挂钩生产单位的合作协议(合同)，提交生产单位的《食品生产许可证》复印件。



















智能客服对接chatgpt开源API

对比chatgpt和我们的

楠哥，找产品组确定故事线





方案：

1. 本地测试，
2. pass 服务器

API-KEY：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

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



### 智能客服



智能客服、chatgpt

**专业性**

**不实时性**



苏州大市内范围内提取公积金还房贷需要准备什么？

1.身份证件原件；

2.银行借款合同原件，公积金贷款（含组合）无需提供；

3.银行指定扣款还贷的银行存折（卡）原件；

4.如申请办理还贷委托提取的职工不是借款人，需提供结婚证或户口簿原件。

职工与中心、贷款银行签订还贷委托提取协议，协议于签订后次月生效，中心于每月18日26日（遇法定假日顺延）提取，5个工作日内将所提取的公积金转入到职工指定的扣款银行账户。

公积金的提取流程



**Q:**外地户口在苏州购房有哪些限购条件？



1.外地户口需提供自购房之日起，3年内在苏州连续6个月及以上纳税或社保证明（2022年5月9日起实施）

2.外地户口，无需社保、个税，可在吴江、太仓、昆山购买1套房。

3.外地户口，卖房后2年内，无需社保或税单可直接购房（2022年4月11日起）

4.相城区外地人买首套房，600积分政策取消（2022年9月20日起）

5.吴江汾湖：上海、嘉善户口，无需社保，可在汾湖买3套房；外地户籍缴纳1个月上海社保，大专以上学历，可在汾湖买1套房

6.苏州大市范围内，昆山、太仓、相城区出具人才编码以及姑苏区、工业园区、高新区、吴中区、吴江区达到人才认定标准，可以购买3套房（即与本地户籍同等看待）



1.2019

2.2018

3.2020

4.2021

5.2021

6.2019



2018、2019、2021、2020

1.外地户口，无需社保、个税，可在吴江、太仓、昆山购买1套房;

2.苏州大市范围内，昆山、太仓、相城区出具人才编码以及姑苏区、工业园区、高新区、吴中区、吴江区达到人才认定标准，可以购买3套房（即与本地户籍同等看待）;

3.吴江汾湖：上海、嘉善户口，无需社保，可在汾湖买3套房；外地户籍缴纳1个月上海社保，大专以上学历，可在汾湖买1套房；

4.外地户口，卖房后2年内，无需社保或税单可直接购房（2022年4月11日起）；

5.外地户口需提供自购房之日起，3年内在苏州连续6个月及以上纳税或社保证明（2022年5月9日起实施）；

6.相城区外地人买首套房，600积分政策取消（2022年9月20日起）。



苏州人才落户有哪些条件？

请选择您要查询的类型：

1.学历型人才；

2.职称型（专业技术）人才；

3.技能型人才。

1

1、具有全日制大专学历者35周岁以下(不超过35周岁)或在苏稳就业，并由申报单位连续缴纳（不含补缴）社保6个月以上的
人员，在人事档案转入后可申请办理落户；
2、具有本科学历（含留学人员）、中级技术职称、国家职业资格（职业技能等级）二级条件之一的人员，年龄45周岁以下（不
超过45周岁），在人事档案转入后可申请动理落户，具有全日制本科学历及学士学位以上人员可享受“先落户，后就业”政策；
3、具有硕士研究生学历或硕士学位、高级技术职称、国家职业资格（职业技能等级）一级条件之一的人员，在人事档案转入后
可申请办理落户；
4、留学回国人士，也就是我们常说的“海归”，海外回国人员在国（境）外取得学士及以上学位并取得国家教育部学历学位认
证的留学人员，可先落户后就业，在人事档案转入后可申请办理落户。

2

1、具有高级技术职称的人员；
2、博士研究生、正高级技术职称人员年龄不超过55周岁；
3、硕士研究生、副高级技术职称人员年龄不超过50周岁。

3

1、二级国家职业资格（技能等级）证书(≤45周岁)；一级国家职业资格（技能等级）证书(≤50周岁)；
2、高级（三级）国家职业资格（技能等级）证书(≤35周岁)，需在苏连续缴纳6个月社保（不含补缴）。
其中国家职业资格（技能等级）证书需要是现年度苏州紧缺型工种并且缴纳社保的单位需要和证书工种相匹配。







辽宁省人民政府办公厅关于印发《政策文件解读工作规范（试行）》的通知：http://www.ln.gov.cn/zwgkx/zfwj/zfwj2011_153687/202209/t20220921_4676807.html

《政策文件解读工作规范（试行）》政策解读：http://www.ln.gov.cn/zwgkx/zcjd/202209/t20220921_4676914.html



#### 20230313

公积金可以拿来租房用吗

请问您想咨询的问题是：租房如何提取公积金吗？

1.是

2.否



请问您是否属于以下情况:

1.具有合法产权且符合安全条件的我市出租房屋;

2.用人单位集体宿舍;

3.用人单位租赁的具体合法产权且符合安全条件的我市出租房屋。



1

1.准备好自己和房东签订的租房合同原件及复印件；
2.准备房租完税发票原件及复印件；
3.填写住房公积金提取申请书，于住房公积金管理分理处提交申请书及复印件提交审核；
4.若审核通过，则可通过受委托银行办理公积金的提现，若审核未通过，则需要再次补齐相关材料二次提交。







公积金提取到哪里办还贷委提

暂无匹配到该地区下相关事项，您可以转接人工咨询。





### openai

1.总结并创建主题，从文本块中提取文本信息，生成段落或句子的摘要

12.文本关键词提取    （知识文本挖掘）

7.知识图谱

6.点评生成，根据一段文字生成对其的看法





以下是 OpenAI 的 48 个 API，包括英文名、中文名和中文解释：

1. Codex API：编程助手 API，可生成代码。
2. DALL-E API：图像生成 API，可生成与文本描述相关的图像。
3. GPT-3 API：自然语言生成 API，能够生成文章、对话和故事等文本。
4. CLIP API：图像和文本搜索 API，可通过输入图像或文本来搜索相关的图像或文本。
5. GPT-2 API：自然语言生成 API，能够生成文章、对话和故事等文本。
6. GPT-Neo API：自然语言生成 API，能够生成文章、对话和故事等文本。
7. ADA API：自然语言生成 API，能够生成文章、对话和故事等文本。
8. Curie API：自然语言生成 API，能够生成文章、对话和故事等文本。
9. Babbage API：自然语言生成 API，能够生成文章、对话和故事等文本。
10. Davinci API：自然语言生成 API，能够生成文章、对话和故事等文本。
11. GPT-J API：自然语言生成 API，能够生成文章、对话和故事等文本。
12. GPT-3 Playground：GPT-3 API 的可视化界面，可用于测试和演示 GPT-3 API。
13. LPD-5 API：语言模型 API，可用于文本分类、命名实体识别等任务。
14. Pet API：自然语言生成 API，能够生成文章、对话和故事等文本。
15. Codex Playground：Codex API 的可视化界面，可用于测试和演示 Codex API。
16. GPT-2 Playground：GPT-2 API 的可视化界面，可用于测试和演示 GPT-2 API。
17. DALL-E Playground：DALL-E API 的可视化界面，可用于测试和演示 DALL-E API。
18. CLIP Playground：CLIP API 的可视化界面，可用于测试和演示 CLIP API。
19. GPT-Neo Playground：GPT-Neo API 的可视化界面，可用于测试和演示 GPT-Neo API。
20. ADA Playground：ADA API 的可视化界面，可用于测试和演示 ADA API。
21. Curie Playground：Curie API 的可视化界面，可用于测试和演示 Curie API。
22. Babbage Playground：Babbage API 的可视化界面，可用于测试和演示 Babbage API。
23. Davinci Playground：Davinci API 的可视化界面，可用于测试和演示 Davinci API。
24. GPT-J Playground：GPT-J API 的可视化界面，可用于测试和演示 GPT-J API。
25. Anomaly Detection API：异常检测 API，可用于检测数据中的异常值。
26. Content Filter API：内容过滤 API，可用于检测和过滤不良内容。
27. Dactyl：手部姿势生成 API，可用于生成手部姿势。
28. Data Augmentation API：数据增强 API，可用于生成增强的数据集。
29. Data API：数据集 API，可用于获取和处理数据集。
30. Dense Passage Retrieval (DPR) API：文本检索 API，可用于在文本语料库中检索相关文本。
31. GPT-3 Sandbox：GPT-3 API 的可视化界面，可用于测试和演示 GPT-3 API。
32. Grid API：分布式训练 API，可用于在多台机器上进行训练。
33. Handwriting API：手写识别 API，可用于识别手写文本。
34. Image API：图像处理 API，可用于图像分类、目标检测等任务。
35. Language Model API：语言模型 API，可用于文本分类、命名实体识别等任务。
36. Neural Machine Translation (NMT) API：神经机器翻译 API，可用于将一种语言翻译成另一种语言。
37. Optica API：光学字符识别 API，可用于识别印刷体字符。
38. Question Answering API：问答 API，可用于回答自然语言问题。
39. Semantic Search API：语义搜索 API，可用于搜索相关的文本。
40. Sentiment Analysis API：情感分析 API，可用于分析文本的情感。
41. Summarization API：文本摘要 API，可用于生成文本摘要。
42. Text Classification API：文本分类 API，可用于将文本分类到预定义的类别中。
43. Text Completion API：文本自动补全 API，可用于自动完成文本。
44. Text Generation API：文本生成 API，可用于生成文章、对话和故事等文本。
45. Text Similarity API：文本相似度 API，可用于计算文本之间的相似度。
46. Translation API：翻译 API，可用于将一种语言翻译成另一种语言。
47. Visual Question Answering (VQA) API：视觉问答 API，可用于回答与图像相关的问题。
48. Word Embeddings API：词向量 API，可用于将文本转换为向量表示。















总结下面的政策内容，生成一段解读性质的摘要。



各市人民政府，省政府各厅委、直属机构：
　　中国（辽宁）自由贸易试验区（以下简称辽宁自贸试验区）认真贯彻党中央、国务院决策部署及省委、省政府工作要求，坚持以制度创新为核心，全力推进制度创新实践，形成了辽宁自贸试验区第六批共31项改革创新经验做法。现就借鉴推广辽宁自贸试验区改革创新经验有关事项通知如下。
　　**一、可借鉴推广的主要内容**
　　（一）政府职能转变领域（6项）。科技创新型企业“靶向培育”新机制、“知识产权直通车”服务新机制、商标保护“云鉴定”新模式、工程质量检测智慧监管、饲料与饲料添加剂生产许可审批改革、海关“问题清零”长效机制。
　　（二）贸易便利化领域（5项）。保税卡口智能化、智能引导企业自控远程辅助新模式、海运拼箱涉危业务便捷通关模式、原产地证书“信用签”、跨境出口商品清单布控自动分拣。
　　（三）金融创新领域（5项）。新型离岸贸易管理服务体系、“三贷”中心精准定向金融服务、在华工作境外个人薪酬购汇便利化、人民币贸易融资资产跨境转让通道创新、银行风控数字化转型。
　　（四）税收制度改革领域（4项）。跨省异地电子缴税、税务服务数字化升级、出口退税智能诊断新模式、综保区一般纳税人登记备案“一窗办理”。
　　（五）国资国企改革及产业转型升级领域（6项）。国资国企“反向混改”模式、依托信用资本平台探索国企改革新路径、区属国有企业市场化改革、区属国有企业职业经理人改革、“链网协同”产融合作新模式、工业互联网助力园区数字化服务模式。
　　（六）扩大开放领域（5项）。国际航行船舶“绿色直通车”边检服务模式、自贸协定优惠税率分析服务系统、RCEP背景下税收事先裁定服务机制、国际艺术品保税展示新模式、进口汽车全过程监管数字化新模式。
　　**二、工作要求**
　　（一）加强组织实施。各市政府要因地制宜，将借鉴推广相关改革创新经验列为本地区重点工作，建立健全领导机制，增强服务意识，提高监管水平，有效防控风险，确保改革试点经验落地生根，产生实效。
　　（二）加强政策宣传解读。各地区、各有关单位要加大宣传力度，通过多种渠道宣传解读相关政策，确保各类市场主体知悉政策内涵，引导其用足用好相关政策。
　　（三）加强督促检查。各地区、各有关单位要加强对借鉴推广工作的督促检查，并向省自贸试验区工作领导小组办公室报送工作进展情况。省自贸试验区工作领导小组办公室要牵头做好借鉴推广工作的评估检查，适时将有关工作情况报告省政府。
　　附件：中国（辽宁）自由贸易试验区第六批改革创新经验任务分工表



### OCR测试

公司名称：

```
石家庄星辰企业管理咨询有限公司(张清杰)
石家庄旺道商贸有限公司(王锦)
石家庄蜜拉古特贸易有限公司(李坤)
石家庄承艺工程管理有限公司(张慧莉)
石家庄宝华起重吊装有限公司(王保华)
河北新智获客科技有限公司(周红)
河北欧铮建筑工程有限公司(甄谢)
河北贵熙建筑工程有限公司(张利星)
河北多而佳商贸有限公司(赵亚龙)
河北乐蚁文化传媒有限公司(李亚男)
```





